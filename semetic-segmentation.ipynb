{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12867975,"sourceType":"datasetVersion","datasetId":8139765}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:31:00.884469Z","iopub.execute_input":"2025-08-27T06:31:00.884725Z","iopub.status.idle":"2025-08-27T06:31:16.726341Z","shell.execute_reply.started":"2025-08-27T06:31:00.884697Z","shell.execute_reply":"2025-08-27T06:31:16.725551Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195734.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195801.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192237.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192312.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191605.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193039.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194148.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195829.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194413.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192014.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_190848.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193631.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194215.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195034.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193138.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194526.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193531.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192532.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193906.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195931.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191325.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192746.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200318.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193609.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193120.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195857.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195656.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195401.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194302.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194748.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193433.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192758.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193447.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191944.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192520.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193734.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193022.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191927.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195650.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192102.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191959.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194539.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192749.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194934.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192643.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192056.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192218.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193612.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195922.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194723.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192909.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195223.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193626.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195432.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191936.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191534.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194646.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200143.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193211.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191519.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191751.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195927.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195744.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195707.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200149.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192211.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195435.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192135.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195613.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192404.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192804.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193127.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192445.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193220.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191742.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192527.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193549.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191333.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200214.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192156.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192953.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192354.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194736.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200522.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193143.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192459.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191908.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193546.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194609.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195524.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191931.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200203.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192509.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193839.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191525.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193553.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193113.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200311.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191956.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193541.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192602.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195330.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200254.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194554.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195541.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193102.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192752.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195326.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193019.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192207.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192127.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192550.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192506.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194623.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194709.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193817.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194400.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193718.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193711.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192021.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195755.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200031.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195448.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195059.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193215.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192905.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200221.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193013.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193535.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195257.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191225.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194139.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195047.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193757.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194320.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193706.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194249.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193422.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194316.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192845.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192524.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200540.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193027.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194931.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192118.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195425.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192108.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192332.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191657.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194631.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195604.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192702.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192742.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192739.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200405.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193559.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192429.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195943.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194741.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195421.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193901.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193409.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192026.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193401.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194404.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200037.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195352.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192050.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192638.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_190945.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194543.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194532.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192202.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191911.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194914.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195454.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194727.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191208.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194653.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192606.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192324.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_190853.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193429.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192040.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200348.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194613.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194338.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192706.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191859.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195439.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195903.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194909.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195807.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193726.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194519.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193819.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195700.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194927.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192736.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191947.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191342.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194346.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_190900.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192258.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195936.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192948.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192631.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194246.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194617.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193007.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191640.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192514.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191853.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194637.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192008.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194859.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194703.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194352.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195444.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192319.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200441.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194919.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193406.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193751.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193250.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200355.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195557.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192659.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200437.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192254.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194153.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195109.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193851.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195307.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200233.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194349.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191543.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194224.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200018.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193855.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192413.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193107.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192411.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200158.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194144.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192345.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195536.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191726.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191316.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193714.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193510.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195025.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192853.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200307.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200509.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200315.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194523.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194516.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192536.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194627.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194649.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193835.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194306.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195041.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192722.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200358.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194325.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192031.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200132.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195245.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195029.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195406.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_190843.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195951.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200303.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193240.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200341.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192709.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192230.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200249.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192725.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194718.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200344.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195501.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195055.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191850.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192147.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194200.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195345.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193916.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195253.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195552.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200023.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193413.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200534.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194238.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194903.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200245.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194552.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194924.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191205.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193436.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193426.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200300.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192623.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195417.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192444.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195050.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195249.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191440.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193527.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192649.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200027.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_190905.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192558.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191456.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194242.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192013.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192635.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195910.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191633.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192646.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191920.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193451.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192302.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192338.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192422.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192455.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195749.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192730.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192004.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195312.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191857.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193001.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192241.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192546.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191804.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195813.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193740.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191744.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193502.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194603.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193643.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195609.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200041.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195357.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195822.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192151.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193812.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200519.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200048.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195302.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200238.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192222.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191951.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192651.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194329.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191214.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195619.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200054.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194220.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191413.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200527.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194343.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193418.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_194657.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_190950.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192625.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195428.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191627.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193234.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192438.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_190938.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200225.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193254.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192503.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192609.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193305.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200208.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192613.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191502.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193226.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_190910.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200447.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192418.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200136.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191409.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191622.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200336.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193920.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193617.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191256.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192349.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195741.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195241.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191202.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195411.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191939.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192618.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192714.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193110.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191846.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_200153.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195547.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_192036.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195337.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_195624.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_193832.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/label/IMG_20190726_191221.png\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192324.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195302.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193549.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195619.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192635.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200300.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195041.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192649.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191936.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191850.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192905.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195439.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193113.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194741.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193906.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191225.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192524.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195700.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200048.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193734.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193643.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195307.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193433.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193240.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191744.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191413.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195922.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195249.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194320.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191214.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192004.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200023.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192706.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194302.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195857.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191221.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195253.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192429.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195257.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192118.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193617.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192422.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192013.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192332.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195650.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193110.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192659.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195749.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195707.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195541.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194220.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195927.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194859.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192459.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191939.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193305.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200221.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195345.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194552.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193413.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195829.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200143.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191857.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192026.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192609.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200355.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195050.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192021.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195406.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193215.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192411.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194919.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194924.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200153.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195025.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193426.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200233.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195604.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193120.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200315.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193711.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193527.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192618.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194718.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200136.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195034.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192338.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194657.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200358.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195547.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192008.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195432.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191859.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193107.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192151.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195330.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194631.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192546.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200225.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192218.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194637.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194325.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200336.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192258.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192108.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191456.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195903.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194249.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191633.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_190938.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195744.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193740.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192230.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193546.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193510.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200405.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195524.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192631.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200447.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195223.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200249.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192730.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195656.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_190905.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200203.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193022.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192156.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195055.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191502.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195910.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191519.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193612.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193250.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192725.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194144.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194609.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200534.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192532.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191316.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193559.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194909.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194200.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192102.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192736.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200318.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194623.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195047.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192207.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200527.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194627.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194903.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193226.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200522.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193451.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191853.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193626.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191920.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200540.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191640.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192345.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195609.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194539.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193027.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193406.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192031.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200519.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195312.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195552.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192056.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193855.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194329.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191208.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191911.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195822.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192312.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191931.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191325.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_190848.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193819.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191944.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200344.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195428.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192302.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194238.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192702.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193631.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191804.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195059.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195801.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_190945.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195734.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192643.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192651.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191622.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195807.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195624.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193714.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194526.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200437.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192746.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_190900.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191202.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200509.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_190910.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191409.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195951.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191908.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193757.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_190950.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192606.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195444.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194215.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195417.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191627.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192222.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195029.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192354.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192623.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200303.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192558.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193401.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195536.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194242.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193447.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191951.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193436.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193718.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194352.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191657.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191959.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200027.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200208.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200031.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194723.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195245.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193254.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193531.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193013.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193835.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192147.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194343.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192550.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191947.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192254.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194709.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192602.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193211.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194653.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193234.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194603.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194306.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192520.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193609.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191605.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194617.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192413.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192739.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194338.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192455.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192503.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192418.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200037.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193007.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193418.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191956.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195421.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194349.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194736.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200054.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194404.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194523.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193541.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192536.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194703.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192036.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195943.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192948.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195755.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200238.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193839.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192752.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194646.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195454.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191256.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194224.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193429.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192638.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200245.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192050.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194931.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195357.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192709.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195501.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194413.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193127.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191846.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191440.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192953.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194927.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200018.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194914.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194519.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192444.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193502.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191726.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193220.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200214.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191927.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200149.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192742.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191751.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192625.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192404.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193920.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195109.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191342.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194400.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200132.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192514.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194139.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195411.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191525.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195337.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194346.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193409.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_190843.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194613.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194316.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193916.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191333.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192909.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193706.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192319.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192804.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193102.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200348.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194246.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192135.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192613.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191742.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200311.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192237.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192211.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193138.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193726.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200158.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195326.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194649.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192127.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191543.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192202.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193553.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194554.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192749.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191534.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193039.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_190853.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192014.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192438.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195813.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195241.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193535.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194153.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200341.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194934.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_191205.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200441.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193422.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195936.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195401.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194543.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193812.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192509.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193019.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192722.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192714.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194148.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195425.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194532.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195931.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194748.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195741.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193901.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193832.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200254.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192646.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193851.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192445.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194516.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193001.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_194727.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195557.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192527.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193817.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192349.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193751.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192241.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_193143.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192506.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192845.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195613.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200307.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192758.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_200041.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195448.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195352.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_195435.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192040.jpg\n/kaggle/input/apple-dataset/ATLDSD/Healthy leaf/image/IMG_20190726_192853.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004035.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000514.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000750.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000546.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000505.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000444.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000461.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000748.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000808.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000436.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000715.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004111.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000683.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004091.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000769.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000756.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000722.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004069.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000477.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000427.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004093.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000545.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000426.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000787.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000467.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000535.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004021.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000778.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000522.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000818.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000443.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000464.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000784.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004095.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000712.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000473.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000529.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000515.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000460.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000799.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000731.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000431.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004087.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000687.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000664.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000503.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000782.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000423.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000749.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000801.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000742.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004085.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000450.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000466.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000774.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000549.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000707.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000501.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000537.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000496.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000425.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000552.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000764.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000454.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004115.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000694.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000779.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000451.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000711.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004121.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004029.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000511.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000781.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004053.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000743.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000803.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000481.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004047.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000754.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000757.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000456.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004051.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004083.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000816.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000730.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000728.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000741.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000738.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000718.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000739.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000795.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000504.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004103.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000766.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000433.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004079.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000553.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004011.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004033.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000498.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000517.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000468.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004061.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000753.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000449.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000717.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000716.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004049.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000726.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000530.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004005.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000558.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000519.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000413.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000512.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000708.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000429.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000420.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000765.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000796.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000773.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000524.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004075.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004031.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000732.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000488.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000706.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004101.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004077.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000531.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000759.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000453.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000820.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000810.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000780.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000474.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000747.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000421.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000771.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000518.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000735.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000737.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000814.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000751.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004107.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000733.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000534.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000435.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000506.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000475.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000661.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000817.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000673.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004043.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000775.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000559.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000560.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004097.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000709.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000701.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000725.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000719.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004023.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000772.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000472.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004009.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000822.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000768.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004037.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000439.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004003.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004081.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000543.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000510.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000783.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000434.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000526.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000478.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000807.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004105.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004019.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000663.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000418.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000484.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000791.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000699.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000438.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000690.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000767.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000520.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000414.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000761.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000508.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000685.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000494.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004109.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000493.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000744.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004055.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000441.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004007.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000763.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000798.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000507.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000705.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000536.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004073.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000521.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004015.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000544.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000513.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000819.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000502.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000500.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004039.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000785.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004025.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000721.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000697.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000462.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000693.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000686.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000509.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000495.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000525.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000527.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004041.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000479.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000672.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000448.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004071.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000734.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004017.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000499.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000539.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000797.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000445.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000452.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004057.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000523.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000457.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000776.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000422.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000770.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000497.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000788.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000446.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000459.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000702.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000736.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000532.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004001.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000665.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004067.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000432.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004059.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000430.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004027.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000455.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000416.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004045.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000777.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000762.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000760.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000800.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000813.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000415.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004099.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000740.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000792.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000424.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000659.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004013.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000417.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000555.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000755.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/000729.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/label/004089.png\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000780.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000705.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000748.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000813.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000456.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000763.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000737.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000446.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000518.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000507.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000545.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004067.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000685.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004091.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004105.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000699.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004097.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004041.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000452.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000521.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000785.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000774.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000770.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000717.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000493.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000455.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004071.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004009.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000756.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000478.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000796.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000694.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004027.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000544.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000754.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000472.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000423.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004099.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000474.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000822.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000771.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000414.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000739.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000721.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000772.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004035.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000552.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000690.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000765.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000445.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000460.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000464.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000435.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004055.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000514.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000505.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000729.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000426.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000543.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000511.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000759.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004043.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000707.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000747.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000814.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000422.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000773.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000441.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004081.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000421.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004075.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000418.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000709.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004087.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000462.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000459.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000466.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004121.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000782.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000477.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000433.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000799.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004053.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000461.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000512.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000519.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004015.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000741.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000750.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000683.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000431.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004007.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004103.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000663.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004051.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000467.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000495.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000416.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000420.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004073.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000450.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000769.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000499.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004101.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000775.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004023.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004013.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000778.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000436.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000701.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000498.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000496.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000549.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000736.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000425.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000686.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000725.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000468.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000697.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000760.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000762.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000664.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000687.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000722.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000711.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000788.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000728.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000532.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000524.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000712.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000718.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000525.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000820.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000738.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000523.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004045.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004079.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000784.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000726.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000693.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000751.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000787.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000453.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004095.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000488.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000742.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000753.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000539.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000665.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000661.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004019.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000509.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004059.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000731.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004057.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000659.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000764.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004025.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000513.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004107.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000818.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000536.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000558.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004003.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000749.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000766.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000819.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000522.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000530.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004029.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000475.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004011.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000503.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004085.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000413.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000517.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000439.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004111.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000515.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000444.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000797.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000740.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000777.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000537.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000520.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000448.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000424.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000733.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000730.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000415.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000808.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000454.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000817.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000502.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000803.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000553.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000501.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000434.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000743.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000719.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004093.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000527.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000531.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000504.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000810.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004083.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000481.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000816.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000559.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000560.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004037.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004005.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000800.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000791.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000500.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004017.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000457.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004021.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000767.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000801.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000473.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004077.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000757.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000430.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000449.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000417.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004049.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000807.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000526.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004033.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000755.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000451.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000497.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004039.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000734.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000708.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000546.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004061.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000529.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004089.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000716.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004031.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000798.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000744.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000732.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000432.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000429.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000783.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000781.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000672.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004115.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000715.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000779.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000761.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000706.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000555.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000443.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004001.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004109.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000535.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000792.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000510.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004069.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000484.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000795.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000776.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000702.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000479.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000768.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000534.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000427.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000508.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/004047.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000735.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000438.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000506.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000494.jpg\n/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000673.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162731.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164357.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004779.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004191.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004317.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164151.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004185.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004241.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163204.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004303.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004127.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004733.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004609.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004541.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004673.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004443.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004385.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004263.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163140.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004761.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163918.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004835.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004503.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004285.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004559.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163717.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004173.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004635.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004401.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162917.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163706.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004721.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004663.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004737.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004223.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004409.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004527.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163736.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164331.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004793.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004685.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004625.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004791.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004419.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004847.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163919.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004573.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164025.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004343.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004867.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163558.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162809.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162703.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004705.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163950.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163642.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163643.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162655.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004165.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004431.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004237.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004371.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004815.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004557.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004757.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004261.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004407.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164038.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004515.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004599.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004143.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004581.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004707.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163517.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004633.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004831.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004373.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004229.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004415.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004735.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004475.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163245.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004561.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004161.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004853.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004837.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004179.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004811.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004595.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004615.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004289.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162823.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004141.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164116.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004651.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163805.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004417.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004861.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004381.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163406.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004563.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163726.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004209.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163407.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163059.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004297.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004695.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164334.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004199.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004271.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004197.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162752.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004437.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004655.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163753.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164133.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004753.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004315.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004767.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004235.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004569.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004567.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004857.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004533.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163727.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163234.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004395.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004641.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162710.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162740.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004183.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004327.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004875.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004781.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164421.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004661.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004457.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004719.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004221.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162905.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163825.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004565.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164239.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004265.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004523.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004543.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004627.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162723.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004519.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004833.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004467.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164018.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004843.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164439.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004323.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004747.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164137.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004427.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004397.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004333.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004749.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164419.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004145.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163112.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004653.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004745.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163029.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004617.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004429.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004649.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004301.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162846.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004869.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004647.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004169.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004551.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004525.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163347.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163953.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004637.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163213.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163631.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163607.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004809.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163652.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004803.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164242.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004433.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164455.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004855.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163906.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164105.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004295.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004755.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004681.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004175.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004621.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004711.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004769.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004299.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004603.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004167.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004851.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163357.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004827.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004287.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162857.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004353.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004535.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162937.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004435.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004341.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004239.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164433.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004253.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004785.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004773.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004321.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004693.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004799.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004825.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004677.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004859.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004591.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004451.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004367.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163907.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004281.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163931.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004829.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163153.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004439.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004631.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163716.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004871.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004177.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004479.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004703.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004717.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004513.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004601.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004359.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004355.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163929.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004131.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004645.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004379.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004509.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004683.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004133.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004473.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004255.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004189.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004375.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004461.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163850.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163018.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004135.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004813.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004723.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164104.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164211.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004447.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004345.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004477.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163503.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163628.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164300.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162759.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004497.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004787.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004819.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004469.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004845.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004501.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163854.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_162836.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004485.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004483.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004493.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004171.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004795.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163123.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004783.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164305.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004823.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163426.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004639.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163225.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004403.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004259.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004481.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004839.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004499.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004357.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004129.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004445.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163805_1.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004873.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163735.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164400.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163653.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004205.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163705.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163613.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004629.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163835.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004505.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004181.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004363.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004665.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004383.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004777.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004863.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004643.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004751.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004865.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004227.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163339.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004389.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004163.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004309.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004667.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004463.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004807.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004739.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004583.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004291.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004325.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004571.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004659.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163358.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004441.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004759.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004369.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163009.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004517.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004207.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004805.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004547.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_164042.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004187.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/004679.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/label/IMG_20190727_163438.png\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004633.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004221.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162917.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164018.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004663.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004705.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004781.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004833.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004197.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164211.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004419.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163059.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004723.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163825.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163835.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164455.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004561.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004127.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004373.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004367.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004773.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004309.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004183.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004851.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004803.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004747.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004503.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004509.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004807.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004655.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004375.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004603.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004427.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004343.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004679.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163558.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004253.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004395.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004191.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004829.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004501.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004869.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004133.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004397.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004647.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163213.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163123.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004297.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004831.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004357.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004223.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163613.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004533.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004475.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162740.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004651.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004469.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163717.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004617.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004745.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004749.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163438.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164357.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004547.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162703.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004681.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004479.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163225.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163426.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004813.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004739.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004783.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163009.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004301.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004447.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164419.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004819.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004815.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004177.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163029.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004259.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004205.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004769.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004837.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004401.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004859.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163850.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004371.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004599.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004861.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004241.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163716.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162731.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004711.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004591.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004855.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004759.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004477.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163918.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004263.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004437.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163906.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163953.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163652.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164239.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004317.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004513.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163854.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163653.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004643.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004661.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163642.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004515.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004665.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004385.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004187.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004131.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004795.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004811.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004835.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004777.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004169.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004457.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004207.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163406.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004865.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004355.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004717.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163407.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004261.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004653.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163245.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004165.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162846.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004787.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163726.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164242.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004843.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163517.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004525.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004559.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004527.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004631.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004235.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162905.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164439.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004431.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004565.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004857.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163919.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162752.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164104.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004707.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004451.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004847.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004383.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162937.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004791.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004785.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004291.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004135.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004793.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004695.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004493.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004685.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163929.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004379.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004265.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004827.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004551.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004255.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163735.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164133.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004693.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004519.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004757.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162809.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004341.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004823.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004615.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163907.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004175.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004499.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163018.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004637.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004535.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162836.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163347.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004285.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004345.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163736.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004463.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004429.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004805.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004733.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163234.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004325.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164334.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004505.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163705.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004271.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004761.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162857.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004641.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004417.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162710.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004583.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004237.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004721.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004415.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004673.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004523.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004719.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004353.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004229.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004181.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163643.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004659.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004315.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004129.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004571.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004737.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004481.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164151.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004369.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004287.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004767.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004433.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004141.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004189.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004517.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004825.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164137.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164116.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004483.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164400.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163339.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004303.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004635.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164025.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163931.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004541.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004209.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004873.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004445.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004363.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004333.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004167.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163607.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163631.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004289.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163727.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004281.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004621.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004645.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004609.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163950.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004239.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004389.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004143.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004755.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004703.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004845.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162723.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004323.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004441.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004407.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004409.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004595.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004867.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163112.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163358.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004381.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162823.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004321.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164421.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004581.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004161.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004403.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004735.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164038.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004227.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004473.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004809.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004677.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004683.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004649.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164042.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164300.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004629.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004667.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004839.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162759.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004485.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004443.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004299.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004751.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004295.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164305.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163204.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163805_1.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004753.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164331.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004467.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163357.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004497.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163753.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004563.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163140.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004359.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163503.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004171.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004573.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004627.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004871.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164105.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004875.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163805.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004639.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004435.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163628.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163706.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004601.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004179.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004461.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004853.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004145.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004799.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004439.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_164433.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004863.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004199.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004567.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_163153.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004185.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004569.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004163.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004173.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004779.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004557.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004625.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004543.JPG\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/IMG_20190727_162655.jpg\n/kaggle/input/apple-dataset/ATLDSD/Rust/image/004327.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003065.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_191938.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/001593.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003141.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003053.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003679.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003025.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003395.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003035.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003293.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003029.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150741.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150443.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003491.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003009.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003161.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003275.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003585.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003233.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003153.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150513.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193204.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150730.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003735.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003287.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003043.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003697.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003541.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003163.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003169.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003019.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003121.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003105.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003345.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193644.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150753.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193829.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003729.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003397.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003157.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003097.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003143.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003375.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_192153.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003323.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003483.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003069.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003125.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003183.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003241.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003289.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003547.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003645.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003373.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150713.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003357.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194718.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003147.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_195205.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_195216.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003629.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003571.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003329.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003641.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003699.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003577.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150531.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_191742.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003227.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003501.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194647.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003545.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003117.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003307.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003083.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003511.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003581.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003027.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003587.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003493.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003075.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150329.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003667.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003727.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193256.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003713.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194422.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003261.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003017.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003103.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150525.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003197.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003085.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_195538.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003337.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003673.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003353.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003127.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003257.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003145.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003305.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003245.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003131.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003079.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150700.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194856.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/001651.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003495.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193551.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003339.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003499.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150808.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003669.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003643.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003563.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003031.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003589.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003315.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150437.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150747.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003555.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003625.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193032.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003513.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/001649.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003619.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003319.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003621.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003047.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003717.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194819.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003201.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003685.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003583.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_192606.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003509.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003149.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003341.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003159.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003347.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003591.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003255.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003239.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_192320.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003049.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003111.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003497.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003725.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003539.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003535.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003723.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003187.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003061.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003177.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003661.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003091.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003055.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003099.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003655.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003487.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003095.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150735.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194807.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003185.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003719.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_191326.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003705.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003051.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003529.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150719.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003171.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003067.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003333.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/001591.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003151.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003205.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003677.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_191943.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003087.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003687.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003003.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150614.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003115.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003295.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003595.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003559.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003063.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003609.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193116.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003615.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003077.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003277.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003575.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_195119.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003283.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003247.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003265.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003711.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003273.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003701.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003317.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150538.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003605.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003179.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_192316.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150324.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003573.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003607.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003707.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003689.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003119.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003523.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003349.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003093.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003715.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003569.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193832.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003015.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150501.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003133.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003107.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003733.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003071.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003253.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003401.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003057.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003637.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003703.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003011.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003311.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/001587.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194424.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003517.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003543.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150520.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003731.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003737.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003611.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003631.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003137.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003647.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003683.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003331.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003533.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003109.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150725.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003695.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003657.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003531.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003175.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003299.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003519.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003479.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150706.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003369.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003557.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003023.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003527.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003671.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003313.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003481.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003209.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003039.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003129.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003355.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003113.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003189.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003649.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003359.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193640.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003165.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003635.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003211.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003221.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003549.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003155.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003217.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003485.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003089.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194526.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003251.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003281.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003659.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003691.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003335.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003603.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003191.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003351.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003363.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003199.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003537.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003267.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003243.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003279.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003007.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003059.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003521.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003231.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003633.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003477.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003665.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003207.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003681.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003343.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003181.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003193.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003203.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150427.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003041.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003377.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003639.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003475.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003399.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003237.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003327.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003173.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194855.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003561.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003249.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003215.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193300.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003551.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003167.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003325.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003045.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003101.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003271.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003073.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003263.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003195.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_192208.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003709.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194956.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003309.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003553.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003627.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150758.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003259.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194643.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003135.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003303.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150627.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003567.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003081.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003013.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003301.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003225.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003599.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003033.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003235.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003223.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003321.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193202.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_193548.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003721.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150553.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_194553.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003613.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_195415.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003021.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003371.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_191501.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003219.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/20190726_191406.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003593.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003739.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150803.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003489.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003565.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003139.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003651.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003693.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003623.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003503.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003123.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003291.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003617.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150841.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003653.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003663.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003285.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/001589.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003229.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003297.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003505.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003269.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003037.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003525.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003579.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003675.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003597.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150602.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003365.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/IMG_20190727_150541.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/label/003361.png\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003113.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_195415.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003331.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003321.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150614.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003479.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003081.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003509.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003691.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_191938.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003111.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003315.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003319.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003251.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003353.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003549.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003725.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003569.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003333.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003311.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194718.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003129.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194807.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003347.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003027.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003567.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003619.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003611.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194553.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003253.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003233.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003127.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150747.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003475.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003087.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003727.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003363.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150735.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003199.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003151.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003133.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_192153.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003037.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003179.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003719.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150741.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003689.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003477.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003109.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003369.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/001593.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150329.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003329.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003071.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150713.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003141.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003211.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003563.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003499.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003057.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/001591.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003505.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003323.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003139.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003033.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003137.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003259.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150541.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003035.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003491.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003185.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003309.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150706.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_191943.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003077.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003241.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003697.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_191742.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003239.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003721.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003631.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003377.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003295.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003639.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003591.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003225.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003533.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003189.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003299.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003115.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003135.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003305.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_192606.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150627.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193300.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003317.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003267.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003313.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003527.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_195216.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003681.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003173.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003243.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150803.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003677.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003067.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003223.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003343.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003693.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194855.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003003.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003613.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003013.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003039.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003101.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003701.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003009.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150753.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003019.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003053.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003335.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150758.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003147.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003143.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193640.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194956.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003657.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003117.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150841.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003155.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_191501.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150602.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003557.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003577.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_192320.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003061.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194856.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003257.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_192316.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003553.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003617.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003497.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003673.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003007.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003373.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193548.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003641.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003643.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003519.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003683.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003551.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003625.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003595.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150538.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003531.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003075.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194643.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150437.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003149.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150513.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150719.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003165.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003487.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003095.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/001587.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003565.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003161.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003635.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003045.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003107.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150427.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_191326.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003123.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003621.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003227.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003493.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003021.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003703.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003687.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003671.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003247.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003193.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003597.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003529.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_191406.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003209.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003269.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003359.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003051.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003605.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003523.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003069.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193832.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194819.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003503.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003581.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003025.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003157.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003297.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003249.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003285.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003649.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003207.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003623.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003181.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193032.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003583.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003609.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150700.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193644.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_195538.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003665.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003593.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003675.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003235.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003203.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003229.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003729.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003361.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150553.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003273.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003575.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003349.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003645.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003733.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003395.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003539.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003055.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003125.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003599.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003525.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003201.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003653.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150324.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150501.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150531.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003355.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003659.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003511.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193116.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003041.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003093.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003277.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003661.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003589.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003481.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003177.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003607.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003255.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003739.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003171.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003301.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003485.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003221.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003215.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003183.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003265.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003327.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003119.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003063.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003231.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150525.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003555.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003669.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003495.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_195205.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003145.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003397.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003365.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194422.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003099.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150520.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003283.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003337.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003291.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003103.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003287.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150443.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003263.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003191.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003091.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003587.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003351.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150725.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193829.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003345.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003325.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003083.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003559.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003627.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003195.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003017.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003541.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003279.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003603.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003043.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003711.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003307.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003169.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003713.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/001651.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003293.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003399.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003175.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003647.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003059.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003023.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003655.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003489.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003015.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003163.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003705.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003047.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003513.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003031.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003573.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003561.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003521.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003371.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003261.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003073.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003187.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003275.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003049.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003271.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_195119.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193204.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003715.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003571.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003517.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003029.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003159.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193256.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003707.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003545.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003217.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003401.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003281.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003651.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003615.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003121.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003629.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003537.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_192208.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003079.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003205.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/001589.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003699.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003547.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003685.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003737.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003633.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193202.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003339.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003105.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003011.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003303.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003543.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003483.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003585.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003375.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003723.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003219.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003709.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003717.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003663.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003097.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003085.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003357.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003579.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003237.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003637.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003341.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003131.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/001649.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194647.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_193551.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003245.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150730.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/IMG_20190727_150808.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003065.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003695.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003501.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003535.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003679.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003667.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194526.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/20190726_194424.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003731.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003153.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003197.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003289.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003167.JPG\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003735.jpg\n/kaggle/input/apple-dataset/ATLDSD/Gray spot/image/003089.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001669.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001537.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001493.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001791.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001427.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001781.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001849.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001207.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001869.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001091.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001081.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001123.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001251.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001245.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001079.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001813.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001225.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190726_193647.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001161.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001715.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001665.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001435.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001763.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001469.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001019.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001517.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001023.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001859.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001411.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001511.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001275.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001497.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/褐斑病IMG_20190726_190344.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190726_192821.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001279.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001529.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165707.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001793.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001231.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001845.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001239.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001711.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001343.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165313.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001481.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001475.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001015.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/褐斑病IMG_20190726_191215.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165227.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001073.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001751.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001855.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001765.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165034.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001521.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001235.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001803.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001857.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_170259.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001297.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001187.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001817.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001173.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001153.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001189.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001577.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001005.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001203.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001513.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001861.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001053.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001531.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001093.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001215.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001219.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165110.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001157.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001491.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165528.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001057.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001449.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001267.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001503.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001601.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001749.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_170532.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165814.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165721.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_164757.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001423.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/褐斑病IMG_20190726_191100.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001181.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001489.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001217.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165330.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001597.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165626.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001473.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001167.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190726_192719.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001119.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001061.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001075.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001843.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001779.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001209.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001095.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001825.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_170020.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001617.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/褐斑病IMG_20190726_191340.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001865.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165025.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001011.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001441.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001021.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001229.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001255.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_164718.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165858.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001821.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001545.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001729.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001527.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001673.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001835.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/褐斑病IMG_20190726_193906.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001213.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001063.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001459.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001829.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_164647.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001541.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001629.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001505.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001447.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/褐斑病IMG_20190726_193224.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001125.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001515.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190726_192637.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001643.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001709.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001519.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001797.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001099.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165139.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001575.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001175.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001223.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001247.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001611.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165759.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001811.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165259.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001795.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001639.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001831.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001501.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001221.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165250.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001237.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001867.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001289.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001171.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001179.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001641.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001723.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001323.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001785.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001455.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001087.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001263.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/褐斑病IMG_20190726_190315.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/褐斑病IMG_20190726_192226.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001145.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001653.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001027.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001819.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001333.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001233.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_164929.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001815.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001681.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001733.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001571.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001699.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001677.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001273.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001241.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001375.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001097.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001471.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001573.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001277.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001543.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001159.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001799.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001265.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001827.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001737.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001025.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001805.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_164743.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001467.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165053.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001485.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165554.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001783.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001331.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001847.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001839.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/褐斑病IMG_20190726_191634.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001443.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/IMG_20190727_165213.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/label/001687.png\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001229.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165139.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001643.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001441.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001797.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001545.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001215.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001521.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001279.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001273.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001781.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001505.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190726_192719.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001231.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001081.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001123.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001161.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001825.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_170532.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001475.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001025.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001629.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001093.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001063.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001119.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001709.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001543.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001575.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165250.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001529.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001447.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001869.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001485.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001641.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001711.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165554.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001861.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001427.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001537.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001245.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001267.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001763.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001097.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001213.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001217.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001785.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001513.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001835.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001157.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001597.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_164743.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001481.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001783.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001175.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190726_192637.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001061.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001027.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001019.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001503.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001179.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001803.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165528.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001005.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001601.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001459.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001237.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001795.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001517.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001223.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_164718.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001225.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_164929.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001265.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001669.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165721.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001021.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/褐斑病IMG_20190726_192226.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001233.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001423.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001531.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001145.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001289.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001331.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001729.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001677.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001831.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001159.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001489.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/褐斑病IMG_20190726_190315.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001239.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001087.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165110.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001075.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001811.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165034.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001541.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001817.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001611.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001411.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001171.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001091.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001251.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001497.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001187.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_170020.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165814.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001799.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001865.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001515.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001333.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001653.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001073.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001571.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165313.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001733.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001827.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001737.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001435.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001501.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/褐斑病IMG_20190726_191634.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/褐斑病IMG_20190726_191340.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165053.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165025.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001167.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001855.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001791.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001829.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165213.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001765.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001857.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/褐斑病IMG_20190726_191100.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001805.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001749.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001839.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001053.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190726_192821.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001821.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001125.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_170259.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001493.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165858.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001819.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001491.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001469.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001203.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001173.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001153.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001443.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001859.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001573.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001813.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001219.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001011.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001221.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001665.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001867.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001843.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001079.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/褐斑病IMG_20190726_190344.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001015.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001779.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001577.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001699.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001527.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001467.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/褐斑病IMG_20190726_193224.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001323.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001681.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001715.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001673.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190726_193647.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001849.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001511.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001751.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001275.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001343.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001255.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001639.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001473.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001277.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001023.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165330.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001723.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/褐斑病IMG_20190726_193906.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001189.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001181.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001793.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001241.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001095.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_164757.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165759.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001263.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165227.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001815.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165626.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001207.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001455.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001519.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165259.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001235.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001099.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001209.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001471.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/褐斑病IMG_20190726_191215.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001247.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001297.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001617.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_165707.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001057.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001687.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001449.JPG\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001845.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001847.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/IMG_20190727_164647.jpg\n/kaggle/input/apple-dataset/ATLDSD/Brown spot/image/001375.JPG\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"print (\"hello ' world'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T05:10:45.991806Z","iopub.execute_input":"2025-08-31T05:10:45.992102Z","iopub.status.idle":"2025-08-31T05:10:45.999850Z","shell.execute_reply.started":"2025-08-31T05:10:45.992079Z","shell.execute_reply":"2025-08-31T05:10:45.999018Z"}},"outputs":[{"name":"stdout","text":"hello ' world'\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# =========================================================\n# Apple Leaf Segmentation - MULTI-MODEL COMPARISON\n# UNet, DeepLabV3+, FCN, SegNet, BiSeNetV2\n# Dice + Weighted CE, IoU(no-bg), tf.data Aug, Curves, Comparison\n# Adds visualization: Image | GT | Pred + per-class disease severity (% of leaf)\n# =========================================================\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nos.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\nos.environ[\"TF_DISABLE_PROFILER\"] = \"1\"\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport pandas as pd\nimport time\nimport random\n\n# ============ Config ============\nBASE_DIR    = \"/kaggle/input/apple-dataset/ATLDSD\"   # <--- change if needed\nIMG_SIZE    = 256\nBATCH_SIZE  = 8\nEPOCHS      = 15\nSEED        = 2025\n\n# ==== Resume / Skip settings =====\nOUTDIR = \"outputs\"\nSKIP_TRAIN_IF_CKPT = True         # if checkpoint exists, skip training that model\nRUN_ONLY = None                    # e.g. ['DeepLabV3Plus','BiSeNetV2'] or None\nSTART_AT = None                    # e.g. 'FCN' to skip earlier models\n\nrandom.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n\nCLASS_NAMES = [\n    \"Background\",           # 0\n    \"Healthy\",              # 1\n    \"Brown spot\",           # 2\n    \"Alternaria leaf spot\", # 3\n    \"Gray spot\",            # 4\n    \"Rust\"                  # 5\n]\nNUM_CLASSES = len(CLASS_NAMES)\n\n# exact RGB colors -> class index\nCOLOR_MAP = {\n    (0,   0,   0): 0,   # Background\n    (128, 0,   0): 1,   # Healthy\n    (128, 0, 128): 2,   # Brown spot (purple)\n    (128,128,  0): 3,   # Alternaria (olive)\n    (0,   0, 128): 4,   # Gray (blue)\n    (0, 128,   0): 5,   # Rust (green)\n}\nCLASS_WEIGHTS = tf.constant([0.25, 0.7, 1.1, 1.1, 1.1, 1.2], dtype=tf.float32)\n\n# augmentation knobs\nA_ROT90_PROB   = 0.75\nA_FLIP_H_PROB  = 0.5\nA_FLIP_V_PROB  = 0.5\nA_JITTER_PROB  = 0.6\nA_NOISE_PROB   = 0.3\nA_CROP_PROB    = 0.6\nCROP_MIN_FRAC  = 0.85\n\n# ============ Utils ============\ndef set_gpu_growth():\n    try:\n        gpus = tf.config.list_physical_devices('GPU')\n        if gpus:\n            for g in gpus:\n                tf.config.experimental.set_memory_growth(g, True)\n            print(f\"✅ GPU found: {len(gpus)}; memory growth enabled\")\n        else:\n            print(\"ℹ️  No GPU detected; running on CPU\")\n    except Exception as e:\n        print(\"⚠️  GPU mem-growth not set:\", e)\nset_gpu_growth()\n\ndef rgb_mask_to_classes(mask_rgb):\n    out = np.zeros(mask_rgb.shape[:2], dtype=np.uint8)\n    R, G, B = mask_rgb[...,0], mask_rgb[...,1], mask_rgb[...,2]\n    for (r,g,b), cls in COLOR_MAP.items():\n        m = (R == r) & (G == g) & (B == b)\n        out[m] = cls\n    return out\n\nPALETTE = {\n    0:(0,0,0), 1:(128,0,0), 2:(128,0,128), 3:(128,128,0), 4:(0,0,128), 5:(0,128,0)\n}\ndef mask_to_color(mask):\n    h,w = mask.shape\n    out = np.zeros((h,w,3), dtype=np.uint8)\n    for c, col in PALETTE.items():\n        out[mask==c] = col\n    return out\n\n# ===================== Severity Utils & Visualization =====================\n\ndef compute_severity_percentages(mask_int):\n    \"\"\"\n    Compute severity % per class with respect to LEAF area (non-background).\n    mask_int: [H,W] uint8 class map (0=background, 1=healthy, 2..=diseases)\n    Returns: (per_class_dict, healthy_pct, disease_total_pct)\n    \"\"\"\n    m = np.asarray(mask_int, dtype=np.uint8)\n    leaf = (m != 0)\n    leaf_pixels = int(leaf.sum())\n    if leaf_pixels == 0:\n        # No leaf pixels; avoid div by zero\n        per_class = {CLASS_NAMES[c]: 0.0 for c in range(2, NUM_CLASSES)}\n        healthy_pct = 0.0\n        disease_total = 0.0\n        return per_class, healthy_pct, disease_total\n\n    per_class = {}\n    for c in range(2, NUM_CLASSES):\n        per_class[CLASS_NAMES[c]] = 100.0 * float((m == c).sum()) / leaf_pixels\n\n    healthy_pct = 100.0 * float((m == 1).sum()) / leaf_pixels\n    disease_total = 100.0 - healthy_pct\n    return per_class, healthy_pct, disease_total\n\n\ndef _box_text_from_severity(per_class, healthy_pct, disease_total):\n    \"\"\"\n    Build a neat multi-line text block for overlay.\n    \"\"\"\n    lines = [f\"Healthy: {healthy_pct:5.1f}%\",\n             f\"Total disease: {disease_total:5.1f}%\"]\n    # List each disease class on new line\n    for name, pct in per_class.items():\n        lines.append(f\"{name}: {pct:5.1f}%\")\n    return \"\\n\".join(lines)\n\n\ndef visualize_with_severity(model, Xv, Yv_int, n=4, outdir=\"outputs\", seed=2025):\n    \"\"\"\n    Show Image | GT | Pred with severity (%) boxes.\n    - model: trained Keras model\n    - Xv:   [N,H,W,3] float32 images (0..1)\n    - Yv_int: [N,H,W] uint8 integer masks (class ids)\n    - n: how many samples to draw\n    \"\"\"\n    np.random.seed(seed)\n    os.makedirs(outdir, exist_ok=True)\n    idx = np.random.choice(len(Xv), size=min(n, len(Xv)), replace=False)\n\n    fig, axs = plt.subplots(len(idx), 3, figsize=(11, 3.6*len(idx)))\n    if len(idx) == 1:\n        axs = np.expand_dims(axs, 0)\n\n    for r, i in enumerate(idx):\n        img = Xv[i]\n        gt  = Yv_int[i].astype(np.uint8)\n\n        # Predict\n        pr  = model.predict(img[None], verbose=0)[0]       # [H,W,C]\n        pm  = np.argmax(pr, axis=-1).astype(np.uint8)      # [H,W]\n\n        # Compute severities (GT & Pred)\n        gt_per, gt_healthy, gt_dis = compute_severity_percentages(gt)\n        pr_per, pr_healthy, pr_dis = compute_severity_percentages(pm)\n\n        # Left: Image\n        axs[r,0].imshow(img)\n        axs[r,0].set_title(\"Image\")\n        axs[r,0].axis('off')\n\n        # Middle: GT + severity box\n        axs[r,1].imshow(mask_to_color(gt))\n        axs[r,1].set_title(\"Ground Truth\")\n        axs[r,1].axis('off')\n        gt_txt = _box_text_from_severity(gt_per, gt_healthy, gt_dis)\n        axs[r,1].text(\n            0.02, 0.98, gt_txt,\n            transform=axs[r,1].transAxes,\n            va='top', ha='left',\n            fontsize=9,\n            bbox=dict(facecolor='white', alpha=0.75, edgecolor='black', boxstyle='round,pad=0.4')\n        )\n\n        # Right: Pred + severity box\n        axs[r,2].imshow(mask_to_color(pm))\n        axs[r,2].set_title(f\"Predicted ({model.name})\")\n        axs[r,2].axis('off')\n        pr_txt = _box_text_from_severity(pr_per, pr_healthy, pr_dis)\n        axs[r,2].text(\n            0.02, 0.98, pr_txt,\n            transform=axs[r,2].transAxes,\n            va='top', ha='left',\n            fontsize=9,\n            bbox=dict(facecolor='white', alpha=0.75, edgecolor='black', boxstyle='round,pad=0.4')\n        )\n\n    plt.tight_layout()\n    save_path = os.path.join(outdir, f\"viz_with_severity_{model.name}.png\")\n    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n    plt.close()\n    print(f\"🖼️  Saved severity visualization: {save_path}\")\n    return save_path\n\n# ============ Dataset ============\nclass AppleLeafDataset:\n    IMG_EXTS = (\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\")\n    def __init__(self, base_dir, image_size=256):\n        self.base_dir = base_dir\n        self.image_size = image_size\n        self.image_paths, self.mask_paths = self._discover_pairs()\n        print(f\"✅ Paired samples: {len(self.image_paths)}\")\n\n    def _list_images(self, d):\n        acc = []\n        for r,_,fs in os.walk(d):\n            for f in fs:\n                if f.lower().endswith(self.IMG_EXTS):\n                    acc.append(os.path.join(r,f))\n        return acc\n\n    def _discover_pairs(self):\n        imgs, msks = [], []\n        if not os.path.exists(self.base_dir):\n            raise FileNotFoundError(f\"Base dir not found: {self.base_dir}\")\n        for cls_folder in sorted(os.listdir(self.base_dir)):\n            cpath = os.path.join(self.base_dir, cls_folder)\n            if not os.path.isdir(cpath): continue\n            img_dir = os.path.join(cpath, \"image\")\n            msk_dir = os.path.join(cpath, \"label\")\n            if not (os.path.exists(img_dir) and os.path.exists(msk_dir)): continue\n\n            img_files = self._list_images(img_dir)\n            msk_files = self._list_images(msk_dir)\n            img_by = {os.path.splitext(os.path.basename(p))[0].lower(): p for p in img_files}\n            msk_by = {os.path.splitext(os.path.basename(p))[0].lower(): p for p in msk_files}\n            common = sorted(set(img_by) & set(msk_by))\n            print(f\"📂 {cls_folder:20} | imgs:{len(img_files):4d} | masks:{len(msk_files):4d} | paired:{len(common):4d}\")\n            for s in common: imgs.append(img_by[s]); msks.append(msk_by[s])\n        return imgs, msks\n\n    def load(self):\n        X, Y = [], []\n        for ip, mp in tqdm(list(zip(self.image_paths, self.mask_paths)), desc=\"Loading data\"):\n            img = cv2.imread(ip, cv2.IMREAD_COLOR)\n            if img is None: continue\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_AREA)\n            img = img.astype(np.float32)/255.0\n\n            msk = cv2.imread(mp, cv2.IMREAD_COLOR)\n            if msk is None: continue\n            msk = cv2.cvtColor(msk, cv2.COLOR_BGR2RGB)\n            msk = cv2.resize(msk, (self.image_size, self.image_size), interpolation=cv2.INTER_NEAREST)\n            msk = rgb_mask_to_classes(msk)\n\n            X.append(img); Y.append(msk)\n        return np.asarray(X, np.float32), np.asarray(Y, np.uint8)\n\n# ============ Augmentation (tf.data) ============\ndef augment_img_mask(img, mask):\n    img = tf.cast(img, tf.float32)\n    mask = tf.cast(mask, tf.int32)\n    mask_3d = tf.expand_dims(mask, axis=-1)\n\n    def apply_transform(transform_func, prob):\n        return tf.cond(\n            tf.random.uniform([]) < prob,\n            lambda: transform_func(img, mask_3d),\n            lambda: (img, mask_3d)\n        )\n\n    def rot90_transform(i, m):\n        k = tf.random.uniform([], 0, 4, dtype=tf.int32)\n        return tf.image.rot90(i, k), tf.image.rot90(m, k)\n\n    img, mask_3d = apply_transform(rot90_transform, A_ROT90_PROB)\n\n    def flip_h(i, m): return tf.image.flip_left_right(i), tf.image.flip_left_right(m)\n    def flip_v(i, m): return tf.image.flip_up_down(i), tf.image.flip_up_down(m)\n    img, mask_3d = apply_transform(flip_h, A_FLIP_H_PROB)\n    img, mask_3d = apply_transform(flip_v, A_FLIP_V_PROB)\n\n    def crop_transform(i, m):\n        shape = tf.shape(i)\n        h, w = shape[0], shape[1]\n        frac = tf.random.uniform([], CROP_MIN_FRAC, 1.0)\n        nh = tf.cast(tf.cast(h, tf.float32) * frac, tf.int32)\n        nw = tf.cast(tf.cast(w, tf.float32) * frac, tf.int32)\n        nh = tf.minimum(nh, h); nw = tf.minimum(nw, w)\n        max_y = tf.maximum(1, h - nh); max_x = tf.maximum(1, w - nw)\n        oy = tf.random.uniform([], 0, max_y, dtype=tf.int32)\n        ox = tf.random.uniform([], 0, max_x, dtype=tf.int32)\n        i_crop = tf.image.crop_to_bounding_box(i, oy, ox, nh, nw)\n        m_crop = tf.image.crop_to_bounding_box(m, oy, ox, nh, nw)\n\n        i_resized = tf.image.resize(i_crop, [h, w], method='bilinear')\n\n        # ensure mask resize is dtype-safe\n        m_crop_f = tf.cast(m_crop, tf.float32)\n        m_resized_f = tf.image.resize(m_crop_f, [h, w], method='nearest')\n        m_resized = tf.cast(tf.round(m_resized_f), tf.int32)\n\n        return i_resized, m_resized\n\n    img, mask_3d = apply_transform(crop_transform, A_CROP_PROB)\n\n    def apply_photometric(i):\n        if tf.random.uniform([]) < A_JITTER_PROB:\n            i = tf.image.random_brightness(i, 0.15)\n            i = tf.image.random_contrast(i, 0.8, 1.2)\n            i = tf.image.random_saturation(i, 0.8, 1.2)\n            i = tf.image.random_hue(i, 0.02)\n            i = tf.clip_by_value(i, 0.0, 1.0)\n        if tf.random.uniform([]) < A_NOISE_PROB:\n            noise = tf.random.normal(tf.shape(i), 0.0, 0.02, dtype=tf.float32)\n            i = tf.clip_by_value(i + noise, 0.0, 1.0)\n        return i\n\n    img = apply_photometric(img)\n    mask = tf.squeeze(mask_3d, axis=-1)\n    return img, mask\n\ndef one_hot(mask):\n    return tf.one_hot(tf.cast(mask, tf.int32), depth=NUM_CLASSES)\n\ndef make_dataset(X, Y, batch_size=8, shuffle=False, augment=False):\n    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n    if shuffle:\n        ds = ds.shuffle(min(len(X), 1024), reshuffle_each_iteration=True)\n    def process(img, mask):\n        img = tf.cast(img, tf.float32)\n        mask = tf.cast(mask, tf.int32)\n        if augment:\n            img, mask = augment_img_mask(img, mask)\n        return img, one_hot(mask)\n    return ds.map(process, num_parallel_calls=tf.data.AUTOTUNE)\\\n             .batch(batch_size)\\\n             .prefetch(tf.data.AUTOTUNE)\n\n# ============ Models ============\n\n# 1) UNet\ndef build_unet(input_shape, num_classes, base=48, drop=0.15):\n    x_in = keras.Input(shape=input_shape)\n    def blk(x,f):\n        x = layers.Conv2D(f,3,padding='same',activation='relu')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(f,3,padding='same',activation='relu')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.SpatialDropout2D(drop)(x)\n        return x\n\n    c1 = blk(x_in, base);        p1 = layers.MaxPooling2D(2)(c1)      # 256->128\n    c2 = blk(p1, base*2);        p2 = layers.MaxPooling2D(2)(c2)      # 128->64\n    c3 = blk(p2, base*4);        p3 = layers.MaxPooling2D(2)(c3)      # 64->32\n    c4 = blk(p3, base*8);        p4 = layers.MaxPooling2D(2)(c4)      # 32->16\n    bn = blk(p4, base*16)\n\n    u6 = layers.Conv2DTranspose(base*8,2,2,padding='same')(bn)         # 16->32\n    u6 = layers.Concatenate()([u6,c4]); c6 = blk(u6, base*8)\n\n    u7 = layers.Conv2DTranspose(base*4,2,2,padding='same')(c6)         # 32->64\n    u7 = layers.Concatenate()([u7,c3]); c7 = blk(u7, base*4)\n\n    u8 = layers.Conv2DTranspose(base*2,2,2,padding='same')(c7)         # 64->128\n    u8 = layers.Concatenate()([u8,c2]); c8 = blk(u8, base*2)\n\n    u9 = layers.Conv2DTranspose(base,2,2,padding='same')(c8)           # 128->256\n    u9 = layers.Concatenate()([u9,c1]); c9 = blk(u9, base)\n\n    out = layers.Conv2D(num_classes,1,activation='softmax')(c9)\n    return keras.Model(x_in, out, name=\"UNet\")\n\n# 2) DeepLabV3+ (fixed pooling resize)\ndef build_deeplabv3plus(input_shape, num_classes):\n    def aspp(x):\n        dims = x.shape[-1]\n        h, w = x.shape[1], x.shape[2]  # ints for fixed input\n\n        # Image-level pooling branch (1x1)\n        pool = layers.GlobalAveragePooling2D()(x)\n        pool = layers.Reshape((1, 1, dims))(pool)\n        pool = layers.Conv2D(256, 1, activation='relu', padding='same')(pool)\n        pool = layers.BatchNormalization()(pool)\n        # from 1x1 -> hxw using factor upsampling\n        pool = layers.UpSampling2D(size=(h, w), interpolation='bilinear')(pool)\n\n        # 1x1 conv branch\n        conv1 = layers.Conv2D(256, 1, activation='relu', padding='same')(x)\n        conv1 = layers.BatchNormalization()(conv1)\n\n        # Atrous branches\n        c6  = layers.Conv2D(256, 3, activation='relu', padding='same', dilation_rate=6)(x);  c6  = layers.BatchNormalization()(c6)\n        c12 = layers.Conv2D(256, 3, activation='relu', padding='same', dilation_rate=12)(x); c12 = layers.BatchNormalization()(c12)\n        c18 = layers.Conv2D(256, 3, activation='relu', padding='same', dilation_rate=18)(x); c18 = layers.BatchNormalization()(c18)\n\n        y = layers.Concatenate()([pool, conv1, c6, c12, c18])\n        y = layers.Conv2D(256, 1, activation='relu', padding='same')(y)\n        y = layers.BatchNormalization()(y)\n        return y\n\n    inputs = keras.Input(shape=input_shape)\n\n    # lightweight backbone\n    x = layers.Conv2D(32, 3, strides=2, padding='same', activation='relu')(inputs)  # 256->128\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)                  # 128->128\n    x = layers.BatchNormalization()(x)\n    low = x  # 128x128\n\n    x = layers.Conv2D(128, 3, strides=2, padding='same', activation='relu')(x)      # 128->64\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)                 # 64->64\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv2D(512, 3, strides=2, padding='same', activation='relu')(x)      # 64->32\n    x = layers.BatchNormalization()(x)                                              # 32x32\n\n    # ASPP + decoder\n    x = aspp(x)                                                                     # 32x32\n    x = layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(x)               # 32->128\n    low = layers.Conv2D(48, 1, activation='relu', padding='same')(low)\n    low = layers.BatchNormalization()(low)\n    x = layers.Concatenate()([x, low])                                              # 128\n    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)               # 128->256\n\n    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=\"DeepLabV3Plus\")\n\n# 3) FCN\ndef build_fcn(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    # Encoder (VGG-like)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(inputs)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x)\n    p1 = layers.MaxPooling2D(2)(x)   # 256->128\n\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(p1)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x)\n    p2 = layers.MaxPooling2D(2)(x)   # 128->64\n\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(p2)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x)\n    p3 = layers.MaxPooling2D(2)(x)   # 64->32\n\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(p3)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x)\n    p4 = layers.MaxPooling2D(2)(x)   # 32->16\n\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(p4)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x)\n    p5 = layers.MaxPooling2D(2)(x)   # 16->8\n\n    # FCN head\n    x = layers.Conv2D(4096,7,padding='same',activation='relu')(p5); x = layers.Dropout(0.5)(x)\n    x = layers.Conv2D(4096,1,activation='relu')(x); x = layers.Dropout(0.5)(x)\n\n    s5 = layers.Conv2D(num_classes,1)(x)\n    s4 = layers.Conv2D(num_classes,1)(p4)\n    s3 = layers.Conv2D(num_classes,1)(p3)\n\n    up2 = layers.Conv2DTranspose(num_classes,4,strides=2,padding='same')(s5)  # 8->16\n    f4  = layers.Add()([up2, s4])\n\n    up4 = layers.Conv2DTranspose(num_classes,4,strides=2,padding='same')(f4)  # 16->32\n    f3  = layers.Add()([up4, s3])\n\n    outputs = layers.Conv2DTranspose(num_classes,16,strides=8,padding='same',activation='softmax')(f3)  # 32->256\n    return keras.Model(inputs, outputs, name=\"FCN\")\n\n# 4) SegNet\ndef build_segnet(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n\n    # Encoder\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(inputs); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x);     x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D(2)(x)  # 256->128\n\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D(2)(x)  # 128->64\n\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D(2)(x)  # 64->32\n\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D(2)(x)  # 32->16\n\n    # Decoder\n    x = layers.UpSampling2D(2)(x)  # 16->32\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n\n    x = layers.UpSampling2D(2)(x)  # 32->64\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n\n    x = layers.UpSampling2D(2)(x)  # 64->128\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n\n    x = layers.UpSampling2D(2)(x)  # 128->256\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n\n    outputs = layers.Conv2D(num_classes,1,activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=\"SegNet\")\n\n# 5) BiSeNetV2 (compact; main head only) — fixed ContextEmbedding (no Lambda)\ndef build_bisenetv2(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n\n    def ConvBNReLU(x, f, k=3, s=1):\n        x = layers.Conv2D(f, k, strides=s, padding='same', use_bias=False)(x)\n        x = layers.BatchNormalization()(x)\n        return layers.ReLU()(x)\n\n    def DWConvBNReLU(x, k=3, s=1):\n        x = layers.DepthwiseConv2D(k, strides=s, padding='same', use_bias=False)(x)\n        x = layers.BatchNormalization()(x)\n        return layers.ReLU()(x)\n\n    # ---------- Detail Branch (kept at /8) ----------\n    def DetailBranch(x):\n        # Stage 1: /2\n        x = ConvBNReLU(x, 64, 3, 2)\n        x = ConvBNReLU(x, 64, 3, 1)\n        x = ConvBNReLU(x, 64, 3, 1)\n        # Stage 2: /4\n        x = ConvBNReLU(x, 64, 3, 2)\n        x = ConvBNReLU(x, 64, 3, 1)\n        x = ConvBNReLU(x, 64, 3, 1)\n        # Stage 3: /8\n        x = ConvBNReLU(x, 128, 3, 2)\n        x = ConvBNReLU(x, 128, 3, 1)\n        x = ConvBNReLU(x, 128, 3, 1)\n        return x  # /8\n\n    # ---------- Semantic Branch (down to /16 with CE, then up to /8) ----------\n    def StemBlock(x):\n        x = ConvBNReLU(x, 16, 3, 2)          # /2\n        x = DWConvBNReLU(x, 3, 1)\n        x = ConvBNReLU(x, 16, 1, 1)\n        x = ConvBNReLU(x, 32, 3, 2)          # /4\n        x = DWConvBNReLU(x, 3, 1)\n        x = ConvBNReLU(x, 32, 1, 1)\n        return x  # /4\n\n    def GEBlock(x, out_ch, stride):\n        in_ch = x.shape[-1]\n        y = DWConvBNReLU(x, 3, stride)     # spatial gather\n        y = ConvBNReLU(y, out_ch, 1, 1)    # expansion\n        if stride == 1 and in_ch == out_ch:\n            y = layers.Add()([x, y])\n        return y\n\n    # No Lambda: broadcast global context with static upsampling\n    def ContextEmbedding(x, ch=128):\n        h = layers.GlobalAveragePooling2D(keepdims=True)(x)  # (B,1,1,C)\n        h = layers.BatchNormalization()(h)\n        h = ConvBNReLU(h, ch, 1, 1)\n        H = input_shape[0] // 16\n        W = input_shape[1] // 16\n        h = layers.UpSampling2D(size=(H, W), interpolation='bilinear')(h)  # 1x1 -> HxW\n        y = layers.Add()([x, h])\n        y = ConvBNReLU(y, ch, 3, 1)\n        return y\n\n    def SemanticBranch(x):\n        x = StemBlock(x)              # /4, 32c\n        x = GEBlock(x, 64, 2)         # /8\n        x = GEBlock(x, 64, 1)\n        x = GEBlock(x, 128, 2)        # /16\n        x = GEBlock(x, 128, 1)\n        x = GEBlock(x, 128, 1)\n        x = ContextEmbedding(x, 128)  # /16 (context)\n        x = layers.UpSampling2D(size=2, interpolation='bilinear')(x)  # /16 -> /8\n        return x  # /8, 128c\n\n    def FeatureFusion(detail, semantic, out_ch=256):\n        x = layers.Concatenate()([detail, semantic])     # /8\n        trunk = ConvBNReLU(x, out_ch, 3, 1)\n        att = layers.GlobalAveragePooling2D(keepdims=True)(trunk)\n        att = ConvBNReLU(att, out_ch // 4, 1, 1)\n        att = layers.Conv2D(out_ch, 1, activation='sigmoid', padding='same')(att)\n        out = layers.Multiply()([trunk, att])\n        out = layers.Add()([trunk, out])\n        return out  # /8\n\n    def SegHead(x, num_classes, up_factor=8):\n        x = ConvBNReLU(x, 128, 3, 1)\n        x = layers.Conv2D(num_classes, 1, padding='same', activation='softmax')(x)\n        x = layers.UpSampling2D(size=up_factor, interpolation='bilinear')(x)  # /8 -> /1\n        return x\n\n    db = DetailBranch(inputs)         # /8\n    sb = SemanticBranch(inputs)       # /8\n    fused = FeatureFusion(db, sb, out_ch=256)\n    outputs = SegHead(fused, num_classes, up_factor=8)  # 32x32 -> 256x256\n    return keras.Model(inputs, outputs, name=\"BiSeNetV2\")\n\n# ============ Loss and Metrics ============\nSMOOTH = 1e-6\n\ndef _resize_to_label(y_pred, y_true):\n    \"\"\"Safety: resize predictions to label size if mismatched.\"\"\"\n    ph = tf.shape(y_pred)[1]; pw = tf.shape(y_pred)[2]\n    th = tf.shape(y_true)[1]; tw = tf.shape(y_true)[2]\n    need = tf.logical_or(tf.not_equal(ph, th), tf.not_equal(pw, tw))\n    def _do():\n        return tf.image.resize(y_pred, (th, tw), method='bilinear')\n    return tf.cond(need, _do, lambda: y_pred)\n\ndef weighted_ce(y_true, y_pred):\n    y_pred = _resize_to_label(y_pred, y_true)\n    w = tf.reduce_sum(CLASS_WEIGHTS * y_true, axis=-1)                 # [B,H,W]\n    ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)      # [B,H,W]\n    return tf.reduce_mean(ce * w)\n\ndef dice_loss_no_bg(y_true, y_pred):\n    y_pred = _resize_to_label(y_pred, y_true)\n    y_true_f = tf.reshape(y_true[...,1:], [-1, NUM_CLASSES-1])\n    y_pred_f = tf.reshape(y_pred[...,1:], [-1, NUM_CLASSES-1])\n    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n    denom = tf.reduce_sum(y_true_f + y_pred_f, axis=0)\n    dice = (2.0 * intersection + SMOOTH) / (denom + SMOOTH)\n    return 1.0 - tf.reduce_mean(dice)\n\ndef combo_loss(y_true, y_pred, alpha=0.5):\n    return alpha * weighted_ce(y_true, y_pred) + (1.0 - alpha) * dice_loss_no_bg(y_true, y_pred)\n\n@tf.function\ndef iou_no_bg(y_true, y_pred):\n    \"\"\"Mean IoU over classes 1..C-1 (vectorized, autograph-safe).\"\"\"\n    y_pred = _resize_to_label(y_pred, y_true)\n    y_true_cls = tf.argmax(y_true, axis=-1)\n    y_pred_cls = tf.argmax(y_pred, axis=-1)\n    y_true_oh = tf.one_hot(y_true_cls, depth=NUM_CLASSES, dtype=tf.float32)\n    y_pred_oh = tf.one_hot(y_pred_cls, depth=NUM_CLASSES, dtype=tf.float32)\n    y_true_f = tf.reshape(y_true_oh, [-1, NUM_CLASSES])\n    y_pred_f = tf.reshape(y_pred_oh, [-1, NUM_CLASSES])\n    inter = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n    union = tf.reduce_sum(y_true_f + y_pred_f - y_true_f * y_pred_f, axis=0)\n    inter_nb = inter[1:]; union_nb = union[1:]\n    iou = tf.where(union_nb > 0.0, inter_nb / (union_nb + 1e-7), 0.0)\n    return tf.reduce_mean(iou)\n\n# ============ Training / Evaluation Helpers ============\ndef compile_model(model):\n    model.compile(\n        optimizer=keras.optimizers.Adam(1e-3),\n        loss=combo_loss,\n        metrics=[iou_no_bg, 'accuracy']\n    )\n    return model\n\ndef plot_history(hist, title, outdir):\n    plt.figure(figsize=(10,4))\n    # loss\n    plt.subplot(1,2,1)\n    plt.plot(hist.history['loss'], label='train')\n    plt.plot(hist.history['val_loss'], label='val')\n    plt.title(f'{title} - Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n    # IoU\n    plt.subplot(1,2,2)\n    plt.plot(hist.history['iou_no_bg'], label='train IoU')\n    plt.plot(hist.history['val_iou_no_bg'], label='val IoU')\n    plt.title(f'{title} - IoU(no-bg)'); plt.xlabel('Epoch'); plt.ylabel('IoU'); plt.legend()\n    plt.tight_layout()\n    os.makedirs(outdir, exist_ok=True)\n    p = os.path.join(outdir, f'{title}_curves.png')\n    plt.savefig(p, dpi=140, bbox_inches='tight')\n    plt.close()\n    return p\n\ndef predict_to_mask(pred):\n    return np.argmax(pred, axis=-1).astype(np.uint8)\n\n# ============ Main ============\ndef main():\n    t0 = time.time()\n    print(\"🔎 Loading dataset...\")\n    ds = AppleLeafDataset(BASE_DIR, IMG_SIZE)\n    X, Y = ds.load()\n\n    # simple split (≈70/15/15)\n    Xtr, Xte, Ytr, Yte = train_test_split(X, Y, test_size=0.15, random_state=SEED, shuffle=True)\n    Xtr, Xva, Ytr, Yva = train_test_split(Xtr, Ytr, test_size=0.1765, random_state=SEED, shuffle=True)\n\n    print(f\"Shapes -> Train: {Xtr.shape}, Val: {Xva.shape}, Test: {Xte.shape}\")\n\n    train_ds = make_dataset(Xtr, Ytr, BATCH_SIZE, shuffle=True, augment=True)\n    val_ds   = make_dataset(Xva, Yva, BATCH_SIZE, shuffle=False, augment=False)\n    test_ds  = make_dataset(Xte, Yte, BATCH_SIZE, shuffle=False, augment=False)\n\n    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n\n    # Name -> builder (order preserved)\n    builders = {\n        'UNet': build_unet,\n        'DeepLabV3Plus': build_deeplabv3plus,\n        'FCN': build_fcn,\n        'SegNet': build_segnet,\n        'BiSeNetV2': build_bisenetv2\n    }\n\n    # decide which to run\n    model_names = list(builders.keys())\n    if START_AT and START_AT in model_names:\n        model_names = model_names[model_names.index(START_AT):]\n    if RUN_ONLY:\n        model_names = [n for n in model_names if n in RUN_ONLY]\n\n    results = []\n    os.makedirs(OUTDIR, exist_ok=True)\n\n    for name in model_names:\n        tf.keras.backend.clear_session()\n        ckpt_path = os.path.join(OUTDIR, f\"{name}_best.keras\")\n\n        if SKIP_TRAIN_IF_CKPT and os.path.exists(ckpt_path):\n            print(f\"⏭️  {name}: checkpoint found -> skipping training, loading for eval\")\n            try:\n                model = keras.models.load_model(ckpt_path, compile=False)\n                compile_model(model)\n            except Exception as e:\n                print(f\"⚠️  Failed to load {name} checkpoint: {e}\")\n                print(f\"🔄 Re-training {name} instead...\")\n                model = builders[name](input_shape, NUM_CLASSES)\n                compile_model(model)\n                cbs = [\n                    keras.callbacks.ModelCheckpoint(\n                        ckpt_path, monitor='val_iou_no_bg', mode='max',\n                        save_best_only=True, save_weights_only=False, verbose=1\n                    ),\n                    keras.callbacks.EarlyStopping(\n                        monitor='val_iou_no_bg', mode='max',\n                        patience=6, restore_best_weights=True\n                    )\n                ]\n                hist = model.fit(train_ds, validation_data=val_ds,\n                                 epochs=EPOCHS, verbose=1, callbacks=cbs)\n                _ = plot_history(hist, name, OUTDIR)\n        else:\n            print(f\"\\n🚀 Training {name} ...\")\n            model = builders[name](input_shape, NUM_CLASSES)\n            compile_model(model)\n            cbs = [\n                keras.callbacks.ModelCheckpoint(\n                    ckpt_path, monitor='val_iou_no_bg', mode='max',\n                    save_best_only=True, save_weights_only=False, verbose=1\n                ),\n                keras.callbacks.EarlyStopping(\n                    monitor='val_iou_no_bg', mode='max',\n                    patience=6, restore_best_weights=True\n                )\n            ]\n            hist = model.fit(train_ds, validation_data=val_ds,\n                             epochs=EPOCHS, verbose=1, callbacks=cbs)\n            _ = plot_history(hist, name, OUTDIR)\n\n        # Evaluate (even if loaded)\n        print(f\"📏 Evaluating {name} ...\")\n        val_metrics  = model.evaluate(val_ds,  verbose=0)\n        test_metrics = model.evaluate(test_ds, verbose=0)\n\n        res = {\n            \"Model\": name,\n            \"Val Loss\": float(val_metrics[0]),\n            \"Val IoU(no-bg)\": float(val_metrics[1]),\n            \"Val Acc\": float(val_metrics[2]),\n            \"Test Loss\": float(test_metrics[0]),\n            \"Test IoU(no-bg)\": float(test_metrics[1]),\n            \"Test Acc\": float(test_metrics[2]),\n        }\n        results.append(res)\n\n        # Preview with severity (%) relative to leaf area\n        _ = visualize_with_severity(model, Xva, Yva, n=4, outdir=OUTDIR)\n\n    # Save/append comparison CSV\n    cmp_csv = os.path.join(OUTDIR, \"model_comparison.csv\")\n    df_new = pd.DataFrame(results)\n    if os.path.exists(cmp_csv):\n        try:\n            df_old = pd.read_csv(cmp_csv)\n            df = (pd.concat([df_old, df_new], ignore_index=True)\n                    .drop_duplicates(subset=['Model'], keep='last'))\n        except Exception:\n            df = df_new\n    else:\n        df = df_new\n    df = df.sort_values(\"Val IoU(no-bg)\", ascending=False)\n    df.to_csv(cmp_csv, index=False)\n    print(\"\\n================ Model Comparison (by Val IoU no-bg) ================\")\n    print(df.to_string(index=False))\n    print(f\"\\n💾 Saved: {cmp_csv}\")\n    print(f\"✅ Done in {time.time()-t0:.1f}s\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T05:10:53.976922Z","iopub.execute_input":"2025-08-31T05:10:53.977684Z","iopub.status.idle":"2025-08-31T06:30:03.165674Z","shell.execute_reply.started":"2025-08-31T05:10:53.977654Z","shell.execute_reply":"2025-08-31T06:30:03.164982Z"}},"outputs":[{"name":"stderr","text":"2025-08-31 05:10:57.826223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756617058.149483      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756617058.236721      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nI0000 00:00:1756617075.286757      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1756617075.287675      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"⚠️  GPU mem-growth not set: Physical devices cannot be modified after being initialized\n🔎 Loading dataset...\n📂 Alternaria leaf spot | imgs: 278 | masks: 278 | paired: 278\n📂 Brown spot           | imgs: 215 | masks: 215 | paired: 215\n📂 Gray spot            | imgs: 395 | masks: 395 | paired: 395\n📂 Healthy leaf         | imgs: 409 | masks: 409 | paired: 409\n📂 Rust                 | imgs: 344 | masks: 344 | paired: 344\n✅ Paired samples: 1641\n","output_type":"stream"},{"name":"stderr","text":"Loading data: 100%|██████████| 1641/1641 [00:22<00:00, 74.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Shapes -> Train: (1147, 256, 256, 3), Val: (247, 256, 256, 3), Test: (247, 256, 256, 3)\n\n🚀 Training UNet ...\nEpoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1756617135.908867      99 service.cc:148] XLA service 0x7956c0001ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1756617135.910125      99 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1756617135.910145      99 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1756617138.182302      99 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1756617184.042244      99 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.6170 - iou_no_bg: 0.1197 - loss: 0.6815","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1756617244.206244      98 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1756617244.444640      98 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1756617245.465277      98 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1756617245.788254      98 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.6175 - iou_no_bg: 0.1199 - loss: 0.6810\nEpoch 1: val_iou_no_bg improved from -inf to 0.06704, saving model to outputs/UNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 829ms/step - accuracy: 0.6181 - iou_no_bg: 0.1201 - loss: 0.6806 - val_accuracy: 0.4121 - val_iou_no_bg: 0.0670 - val_loss: 0.7258\nEpoch 2/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.7853 - iou_no_bg: 0.1811 - loss: 0.5376\nEpoch 2: val_iou_no_bg did not improve from 0.06704\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 374ms/step - accuracy: 0.7854 - iou_no_bg: 0.1812 - loss: 0.5375 - val_accuracy: 0.6992 - val_iou_no_bg: 0.0511 - val_loss: 1.0178\nEpoch 3/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8131 - iou_no_bg: 0.2436 - loss: 0.4851\nEpoch 3: val_iou_no_bg did not improve from 0.06704\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 377ms/step - accuracy: 0.8132 - iou_no_bg: 0.2436 - loss: 0.4850 - val_accuracy: 0.1691 - val_iou_no_bg: 0.0197 - val_loss: 2.8301\nEpoch 4/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.8427 - iou_no_bg: 0.2816 - loss: 0.4548\nEpoch 4: val_iou_no_bg improved from 0.06704 to 0.13858, saving model to outputs/UNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 383ms/step - accuracy: 0.8428 - iou_no_bg: 0.2817 - loss: 0.4547 - val_accuracy: 0.5784 - val_iou_no_bg: 0.1386 - val_loss: 1.0848\nEpoch 5/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8643 - iou_no_bg: 0.2978 - loss: 0.4244\nEpoch 5: val_iou_no_bg did not improve from 0.13858\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 377ms/step - accuracy: 0.8643 - iou_no_bg: 0.2978 - loss: 0.4244 - val_accuracy: 0.6132 - val_iou_no_bg: 0.1137 - val_loss: 0.8991\nEpoch 6/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.8786 - iou_no_bg: 0.3147 - loss: 0.4029\nEpoch 6: val_iou_no_bg improved from 0.13858 to 0.19117, saving model to outputs/UNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 384ms/step - accuracy: 0.8786 - iou_no_bg: 0.3147 - loss: 0.4029 - val_accuracy: 0.8316 - val_iou_no_bg: 0.1912 - val_loss: 0.5709\nEpoch 7/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8934 - iou_no_bg: 0.3442 - loss: 0.3753\nEpoch 7: val_iou_no_bg improved from 0.19117 to 0.36474, saving model to outputs/UNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 386ms/step - accuracy: 0.8934 - iou_no_bg: 0.3442 - loss: 0.3753 - val_accuracy: 0.9222 - val_iou_no_bg: 0.3647 - val_loss: 0.3608\nEpoch 8/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.9054 - iou_no_bg: 0.3457 - loss: 0.3631\nEpoch 8: val_iou_no_bg did not improve from 0.36474\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 377ms/step - accuracy: 0.9054 - iou_no_bg: 0.3458 - loss: 0.3631 - val_accuracy: 0.7447 - val_iou_no_bg: 0.2440 - val_loss: 0.4750\nEpoch 9/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8999 - iou_no_bg: 0.3676 - loss: 0.3509\nEpoch 9: val_iou_no_bg did not improve from 0.36474\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 377ms/step - accuracy: 0.8998 - iou_no_bg: 0.3676 - loss: 0.3510 - val_accuracy: 0.8700 - val_iou_no_bg: 0.3247 - val_loss: 0.3831\nEpoch 10/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.9110 - iou_no_bg: 0.3684 - loss: 0.3485\nEpoch 10: val_iou_no_bg improved from 0.36474 to 0.37470, saving model to outputs/UNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 384ms/step - accuracy: 0.9110 - iou_no_bg: 0.3683 - loss: 0.3485 - val_accuracy: 0.9052 - val_iou_no_bg: 0.3747 - val_loss: 0.3408\nEpoch 11/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.9096 - iou_no_bg: 0.3907 - loss: 0.3328\nEpoch 11: val_iou_no_bg improved from 0.37470 to 0.40801, saving model to outputs/UNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 386ms/step - accuracy: 0.9097 - iou_no_bg: 0.3907 - loss: 0.3328 - val_accuracy: 0.8870 - val_iou_no_bg: 0.4080 - val_loss: 0.3455\nEpoch 12/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.9207 - iou_no_bg: 0.3786 - loss: 0.3356\nEpoch 12: val_iou_no_bg did not improve from 0.40801\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 378ms/step - accuracy: 0.9207 - iou_no_bg: 0.3786 - loss: 0.3356 - val_accuracy: 0.8746 - val_iou_no_bg: 0.2334 - val_loss: 0.5175\nEpoch 13/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.9157 - iou_no_bg: 0.3790 - loss: 0.3385\nEpoch 13: val_iou_no_bg did not improve from 0.40801\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 375ms/step - accuracy: 0.9157 - iou_no_bg: 0.3790 - loss: 0.3385 - val_accuracy: 0.8696 - val_iou_no_bg: 0.3091 - val_loss: 0.4348\nEpoch 14/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.9158 - iou_no_bg: 0.4086 - loss: 0.3192\nEpoch 14: val_iou_no_bg improved from 0.40801 to 0.46771, saving model to outputs/UNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 386ms/step - accuracy: 0.9158 - iou_no_bg: 0.4086 - loss: 0.3192 - val_accuracy: 0.9360 - val_iou_no_bg: 0.4677 - val_loss: 0.2708\nEpoch 15/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.9286 - iou_no_bg: 0.4138 - loss: 0.3110\nEpoch 15: val_iou_no_bg did not improve from 0.46771\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 377ms/step - accuracy: 0.9286 - iou_no_bg: 0.4139 - loss: 0.3109 - val_accuracy: 0.9239 - val_iou_no_bg: 0.3585 - val_loss: 0.3713\n📏 Evaluating UNet ...\n🖼️  Saved severity visualization: outputs/viz_with_severity_UNet.png\n\n🚀 Training DeepLabV3Plus ...\nEpoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"2025-08-31 05:28:45.828185: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f32[512,2592,4,4]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,256,3,3]{3,2,1,0}, f32[2592,256,2,2]{3,2,1,0}), window={size=2x2 pad=1_1x1_1 rhs_reversal=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n2025-08-31 05:28:46.617316: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.789371386s\nTrying algorithm eng4{} for conv (f32[512,2592,4,4]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,256,3,3]{3,2,1,0}, f32[2592,256,2,2]{3,2,1,0}), window={size=2x2 pad=1_1x1_1 rhs_reversal=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n2025-08-31 05:28:52.630579: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f32[512,256,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,2592,4,4]{3,2,1,0}, f32[256,2592,2,2]{3,2,1,0}), window={size=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n2025-08-31 05:28:52.926227: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.295746072s\nTrying algorithm eng4{} for conv (f32[512,256,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,2592,4,4]{3,2,1,0}, f32[256,2592,2,2]{3,2,1,0}), window={size=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - accuracy: 0.7597 - iou_no_bg: 0.1724 - loss: 0.5971","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1756618228.867929      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1756618229.100901      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1756618229.575661      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1756618229.801685      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step - accuracy: 0.7601 - iou_no_bg: 0.1728 - loss: 0.5964\nEpoch 1: val_iou_no_bg improved from -inf to 0.00837, saving model to outputs/DeepLabV3Plus_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 800ms/step - accuracy: 0.7606 - iou_no_bg: 0.1732 - loss: 0.5957 - val_accuracy: 0.1248 - val_iou_no_bg: 0.0084 - val_loss: 1.7147\nEpoch 2/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - accuracy: 0.8606 - iou_no_bg: 0.3246 - loss: 0.4170\nEpoch 2: val_iou_no_bg improved from 0.00837 to 0.07938, saving model to outputs/DeepLabV3Plus_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 487ms/step - accuracy: 0.8607 - iou_no_bg: 0.3247 - loss: 0.4169 - val_accuracy: 0.5205 - val_iou_no_bg: 0.0794 - val_loss: 0.9516\nEpoch 3/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 0.8834 - iou_no_bg: 0.3639 - loss: 0.3759\nEpoch 3: val_iou_no_bg improved from 0.07938 to 0.11903, saving model to outputs/DeepLabV3Plus_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 485ms/step - accuracy: 0.8834 - iou_no_bg: 0.3639 - loss: 0.3759 - val_accuracy: 0.6649 - val_iou_no_bg: 0.1190 - val_loss: 0.7036\nEpoch 4/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.8984 - iou_no_bg: 0.3700 - loss: 0.3534\nEpoch 4: val_iou_no_bg improved from 0.11903 to 0.23902, saving model to outputs/DeepLabV3Plus_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 483ms/step - accuracy: 0.8985 - iou_no_bg: 0.3701 - loss: 0.3533 - val_accuracy: 0.7880 - val_iou_no_bg: 0.2390 - val_loss: 0.4721\nEpoch 5/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.9127 - iou_no_bg: 0.4300 - loss: 0.3093\nEpoch 5: val_iou_no_bg improved from 0.23902 to 0.32847, saving model to outputs/DeepLabV3Plus_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 483ms/step - accuracy: 0.9127 - iou_no_bg: 0.4300 - loss: 0.3092 - val_accuracy: 0.8022 - val_iou_no_bg: 0.3285 - val_loss: 0.3857\nEpoch 6/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 0.9249 - iou_no_bg: 0.4566 - loss: 0.2848\nEpoch 6: val_iou_no_bg improved from 0.32847 to 0.42373, saving model to outputs/DeepLabV3Plus_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 484ms/step - accuracy: 0.9248 - iou_no_bg: 0.4566 - loss: 0.2848 - val_accuracy: 0.9314 - val_iou_no_bg: 0.4237 - val_loss: 0.3017\nEpoch 7/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 0.9259 - iou_no_bg: 0.4669 - loss: 0.2785\nEpoch 7: val_iou_no_bg did not improve from 0.42373\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 480ms/step - accuracy: 0.9258 - iou_no_bg: 0.4669 - loss: 0.2786 - val_accuracy: 0.6990 - val_iou_no_bg: 0.3111 - val_loss: 0.5106\nEpoch 8/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - accuracy: 0.9248 - iou_no_bg: 0.4531 - loss: 0.2888\nEpoch 8: val_iou_no_bg did not improve from 0.42373\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 479ms/step - accuracy: 0.9248 - iou_no_bg: 0.4531 - loss: 0.2887 - val_accuracy: 0.8908 - val_iou_no_bg: 0.3871 - val_loss: 0.3427\nEpoch 9/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.9286 - iou_no_bg: 0.4868 - loss: 0.2636\nEpoch 9: val_iou_no_bg did not improve from 0.42373\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 477ms/step - accuracy: 0.9286 - iou_no_bg: 0.4867 - loss: 0.2636 - val_accuracy: 0.9307 - val_iou_no_bg: 0.3829 - val_loss: 0.3297\nEpoch 10/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.9346 - iou_no_bg: 0.4536 - loss: 0.2842\nEpoch 10: val_iou_no_bg improved from 0.42373 to 0.45008, saving model to outputs/DeepLabV3Plus_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 482ms/step - accuracy: 0.9346 - iou_no_bg: 0.4538 - loss: 0.2840 - val_accuracy: 0.9476 - val_iou_no_bg: 0.4501 - val_loss: 0.2854\nEpoch 11/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.9411 - iou_no_bg: 0.5104 - loss: 0.2486\nEpoch 11: val_iou_no_bg improved from 0.45008 to 0.48339, saving model to outputs/DeepLabV3Plus_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 483ms/step - accuracy: 0.9411 - iou_no_bg: 0.5103 - loss: 0.2486 - val_accuracy: 0.9538 - val_iou_no_bg: 0.4834 - val_loss: 0.2623\nEpoch 12/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.9375 - iou_no_bg: 0.5061 - loss: 0.2523\nEpoch 12: val_iou_no_bg improved from 0.48339 to 0.50130, saving model to outputs/DeepLabV3Plus_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 482ms/step - accuracy: 0.9375 - iou_no_bg: 0.5060 - loss: 0.2523 - val_accuracy: 0.9390 - val_iou_no_bg: 0.5013 - val_loss: 0.2517\nEpoch 13/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.9366 - iou_no_bg: 0.4926 - loss: 0.2588\nEpoch 13: val_iou_no_bg did not improve from 0.50130\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 477ms/step - accuracy: 0.9367 - iou_no_bg: 0.4926 - loss: 0.2587 - val_accuracy: 0.8435 - val_iou_no_bg: 0.4029 - val_loss: 0.3361\nEpoch 14/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 0.9431 - iou_no_bg: 0.5139 - loss: 0.2441\nEpoch 14: val_iou_no_bg improved from 0.50130 to 0.54408, saving model to outputs/DeepLabV3Plus_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 484ms/step - accuracy: 0.9431 - iou_no_bg: 0.5139 - loss: 0.2441 - val_accuracy: 0.9531 - val_iou_no_bg: 0.5441 - val_loss: 0.2261\nEpoch 15/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.9446 - iou_no_bg: 0.5111 - loss: 0.2455\nEpoch 15: val_iou_no_bg did not improve from 0.54408\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 479ms/step - accuracy: 0.9446 - iou_no_bg: 0.5111 - loss: 0.2455 - val_accuracy: 0.9478 - val_iou_no_bg: 0.4982 - val_loss: 0.2524\n📏 Evaluating DeepLabV3Plus ...\n🖼️  Saved severity visualization: outputs/viz_with_severity_DeepLabV3Plus.png\n\n🚀 Training FCN ...\nEpoch 1/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.4122 - iou_no_bg: 0.0680 - loss: 0.6846\nEpoch 1: val_iou_no_bg improved from -inf to 0.11549, saving model to outputs/FCN_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 730ms/step - accuracy: 0.4130 - iou_no_bg: 0.0681 - loss: 0.6842 - val_accuracy: 0.8088 - val_iou_no_bg: 0.1155 - val_loss: 0.5533\nEpoch 2/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.7599 - iou_no_bg: 0.1374 - loss: 0.5450\nEpoch 2: val_iou_no_bg improved from 0.11549 to 0.17996, saving model to outputs/FCN_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 474ms/step - accuracy: 0.7599 - iou_no_bg: 0.1375 - loss: 0.5450 - val_accuracy: 0.8138 - val_iou_no_bg: 0.1800 - val_loss: 0.5044\nEpoch 3/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.7808 - iou_no_bg: 0.1680 - loss: 0.5123\nEpoch 3: val_iou_no_bg improved from 0.17996 to 0.23603, saving model to outputs/FCN_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 474ms/step - accuracy: 0.7809 - iou_no_bg: 0.1681 - loss: 0.5121 - val_accuracy: 0.8226 - val_iou_no_bg: 0.2360 - val_loss: 0.4421\nEpoch 4/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8232 - iou_no_bg: 0.2120 - loss: 0.4738\nEpoch 4: val_iou_no_bg improved from 0.23603 to 0.24524, saving model to outputs/FCN_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 473ms/step - accuracy: 0.8233 - iou_no_bg: 0.2120 - loss: 0.4738 - val_accuracy: 0.8135 - val_iou_no_bg: 0.2452 - val_loss: 0.4343\nEpoch 5/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8312 - iou_no_bg: 0.2306 - loss: 0.4555\nEpoch 5: val_iou_no_bg improved from 0.24524 to 0.33463, saving model to outputs/FCN_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 475ms/step - accuracy: 0.8312 - iou_no_bg: 0.2307 - loss: 0.4554 - val_accuracy: 0.8571 - val_iou_no_bg: 0.3346 - val_loss: 0.3749\nEpoch 6/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8378 - iou_no_bg: 0.3022 - loss: 0.4101\nEpoch 6: val_iou_no_bg did not improve from 0.33463\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 406ms/step - accuracy: 0.8378 - iou_no_bg: 0.3021 - loss: 0.4102 - val_accuracy: 0.8167 - val_iou_no_bg: 0.3279 - val_loss: 0.3870\nEpoch 7/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8536 - iou_no_bg: 0.3346 - loss: 0.3893\nEpoch 7: val_iou_no_bg improved from 0.33463 to 0.39150, saving model to outputs/FCN_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 468ms/step - accuracy: 0.8536 - iou_no_bg: 0.3347 - loss: 0.3892 - val_accuracy: 0.9034 - val_iou_no_bg: 0.3915 - val_loss: 0.3309\nEpoch 8/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8643 - iou_no_bg: 0.3685 - loss: 0.3595\nEpoch 8: val_iou_no_bg improved from 0.39150 to 0.40126, saving model to outputs/FCN_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 476ms/step - accuracy: 0.8643 - iou_no_bg: 0.3685 - loss: 0.3595 - val_accuracy: 0.8876 - val_iou_no_bg: 0.4013 - val_loss: 0.3296\nEpoch 9/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8691 - iou_no_bg: 0.3561 - loss: 0.3653\nEpoch 9: val_iou_no_bg improved from 0.40126 to 0.43235, saving model to outputs/FCN_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 476ms/step - accuracy: 0.8691 - iou_no_bg: 0.3561 - loss: 0.3652 - val_accuracy: 0.9008 - val_iou_no_bg: 0.4323 - val_loss: 0.3032\nEpoch 10/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8722 - iou_no_bg: 0.3846 - loss: 0.3463\nEpoch 10: val_iou_no_bg did not improve from 0.43235\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 403ms/step - accuracy: 0.8722 - iou_no_bg: 0.3846 - loss: 0.3462 - val_accuracy: 0.8833 - val_iou_no_bg: 0.4183 - val_loss: 0.3096\nEpoch 11/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8723 - iou_no_bg: 0.3926 - loss: 0.3406\nEpoch 11: val_iou_no_bg improved from 0.43235 to 0.44996, saving model to outputs/FCN_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 470ms/step - accuracy: 0.8723 - iou_no_bg: 0.3927 - loss: 0.3405 - val_accuracy: 0.9026 - val_iou_no_bg: 0.4500 - val_loss: 0.2930\nEpoch 12/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8882 - iou_no_bg: 0.4362 - loss: 0.3120\nEpoch 12: val_iou_no_bg did not improve from 0.44996\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 406ms/step - accuracy: 0.8882 - iou_no_bg: 0.4360 - loss: 0.3121 - val_accuracy: 0.9058 - val_iou_no_bg: 0.4241 - val_loss: 0.3062\nEpoch 13/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8878 - iou_no_bg: 0.4174 - loss: 0.3219\nEpoch 13: val_iou_no_bg improved from 0.44996 to 0.45640, saving model to outputs/FCN_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 464ms/step - accuracy: 0.8878 - iou_no_bg: 0.4175 - loss: 0.3218 - val_accuracy: 0.9138 - val_iou_no_bg: 0.4564 - val_loss: 0.2865\nEpoch 14/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8990 - iou_no_bg: 0.4457 - loss: 0.2990\nEpoch 14: val_iou_no_bg did not improve from 0.45640\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 406ms/step - accuracy: 0.8990 - iou_no_bg: 0.4456 - loss: 0.2990 - val_accuracy: 0.8891 - val_iou_no_bg: 0.4156 - val_loss: 0.3086\nEpoch 15/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8970 - iou_no_bg: 0.4452 - loss: 0.3002\nEpoch 15: val_iou_no_bg did not improve from 0.45640\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 400ms/step - accuracy: 0.8970 - iou_no_bg: 0.4452 - loss: 0.3002 - val_accuracy: 0.9323 - val_iou_no_bg: 0.4494 - val_loss: 0.2900\n📏 Evaluating FCN ...\n🖼️  Saved severity visualization: outputs/viz_with_severity_FCN.png\n\n🚀 Training SegNet ...\nEpoch 1/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - accuracy: 0.6277 - iou_no_bg: 0.0955 - loss: 0.7040\nEpoch 1: val_iou_no_bg improved from -inf to 0.00471, saving model to outputs/SegNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 731ms/step - accuracy: 0.6283 - iou_no_bg: 0.0956 - loss: 0.7036 - val_accuracy: 0.0152 - val_iou_no_bg: 0.0047 - val_loss: 2.3354\nEpoch 2/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.7991 - iou_no_bg: 0.1537 - loss: 0.5503\nEpoch 2: val_iou_no_bg improved from 0.00471 to 0.06773, saving model to outputs/SegNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 542ms/step - accuracy: 0.7992 - iou_no_bg: 0.1537 - loss: 0.5502 - val_accuracy: 0.3867 - val_iou_no_bg: 0.0677 - val_loss: 1.4044\nEpoch 3/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 0.8149 - iou_no_bg: 0.1766 - loss: 0.5114\nEpoch 3: val_iou_no_bg improved from 0.06773 to 0.12175, saving model to outputs/SegNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 538ms/step - accuracy: 0.8151 - iou_no_bg: 0.1767 - loss: 0.5112 - val_accuracy: 0.7036 - val_iou_no_bg: 0.1218 - val_loss: 0.6839\nEpoch 4/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - accuracy: 0.8712 - iou_no_bg: 0.2276 - loss: 0.4552\nEpoch 4: val_iou_no_bg improved from 0.12175 to 0.12964, saving model to outputs/SegNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 534ms/step - accuracy: 0.8712 - iou_no_bg: 0.2276 - loss: 0.4552 - val_accuracy: 0.6106 - val_iou_no_bg: 0.1296 - val_loss: 0.8813\nEpoch 5/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.8808 - iou_no_bg: 0.2251 - loss: 0.4454\nEpoch 5: val_iou_no_bg improved from 0.12964 to 0.16340, saving model to outputs/SegNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 534ms/step - accuracy: 0.8808 - iou_no_bg: 0.2252 - loss: 0.4454 - val_accuracy: 0.6422 - val_iou_no_bg: 0.1634 - val_loss: 0.5644\nEpoch 6/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.8839 - iou_no_bg: 0.2422 - loss: 0.4319\nEpoch 6: val_iou_no_bg improved from 0.16340 to 0.18215, saving model to outputs/SegNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 535ms/step - accuracy: 0.8839 - iou_no_bg: 0.2422 - loss: 0.4318 - val_accuracy: 0.8093 - val_iou_no_bg: 0.1822 - val_loss: 0.5393\nEpoch 7/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.8921 - iou_no_bg: 0.2431 - loss: 0.4280\nEpoch 7: val_iou_no_bg did not improve from 0.18215\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 528ms/step - accuracy: 0.8921 - iou_no_bg: 0.2431 - loss: 0.4280 - val_accuracy: 0.7560 - val_iou_no_bg: 0.1403 - val_loss: 0.7882\nEpoch 8/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.8982 - iou_no_bg: 0.2441 - loss: 0.4240\nEpoch 8: val_iou_no_bg improved from 0.18215 to 0.27760, saving model to outputs/SegNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 536ms/step - accuracy: 0.8982 - iou_no_bg: 0.2441 - loss: 0.4239 - val_accuracy: 0.9120 - val_iou_no_bg: 0.2776 - val_loss: 0.4035\nEpoch 9/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 0.8965 - iou_no_bg: 0.2686 - loss: 0.4138\nEpoch 9: val_iou_no_bg did not improve from 0.27760\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 529ms/step - accuracy: 0.8965 - iou_no_bg: 0.2686 - loss: 0.4138 - val_accuracy: 0.8707 - val_iou_no_bg: 0.2207 - val_loss: 0.5076\nEpoch 10/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.8740 - iou_no_bg: 0.2536 - loss: 0.4327\nEpoch 10: val_iou_no_bg did not improve from 0.27760\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 527ms/step - accuracy: 0.8741 - iou_no_bg: 0.2537 - loss: 0.4326 - val_accuracy: 0.7634 - val_iou_no_bg: 0.1663 - val_loss: 0.6229\nEpoch 11/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.8793 - iou_no_bg: 0.3036 - loss: 0.3950\nEpoch 11: val_iou_no_bg did not improve from 0.27760\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 527ms/step - accuracy: 0.8794 - iou_no_bg: 0.3037 - loss: 0.3949 - val_accuracy: 0.8264 - val_iou_no_bg: 0.2204 - val_loss: 0.5062\nEpoch 12/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.9009 - iou_no_bg: 0.3100 - loss: 0.3839\nEpoch 12: val_iou_no_bg improved from 0.27760 to 0.32716, saving model to outputs/SegNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 536ms/step - accuracy: 0.9010 - iou_no_bg: 0.3101 - loss: 0.3839 - val_accuracy: 0.9085 - val_iou_no_bg: 0.3272 - val_loss: 0.3788\nEpoch 13/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 0.9027 - iou_no_bg: 0.3253 - loss: 0.3760\nEpoch 13: val_iou_no_bg did not improve from 0.32716\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 529ms/step - accuracy: 0.9027 - iou_no_bg: 0.3254 - loss: 0.3760 - val_accuracy: 0.7059 - val_iou_no_bg: 0.2946 - val_loss: 0.5003\nEpoch 14/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.9056 - iou_no_bg: 0.3393 - loss: 0.3597\nEpoch 14: val_iou_no_bg did not improve from 0.32716\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 528ms/step - accuracy: 0.9056 - iou_no_bg: 0.3393 - loss: 0.3596 - val_accuracy: 0.8463 - val_iou_no_bg: 0.3228 - val_loss: 0.4218\nEpoch 15/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.9149 - iou_no_bg: 0.3524 - loss: 0.3490\nEpoch 15: val_iou_no_bg improved from 0.32716 to 0.33278, saving model to outputs/SegNet_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 537ms/step - accuracy: 0.9149 - iou_no_bg: 0.3525 - loss: 0.3490 - val_accuracy: 0.8765 - val_iou_no_bg: 0.3328 - val_loss: 0.3887\n📏 Evaluating SegNet ...\n🖼️  Saved severity visualization: outputs/viz_with_severity_SegNet.png\n\n🚀 Training BiSeNetV2 ...\nEpoch 1/15\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7615 - iou_no_bg: 0.1612 - loss: 0.5463\nEpoch 1: val_iou_no_bg improved from -inf to 0.07807, saving model to outputs/BiSeNetV2_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 245ms/step - accuracy: 0.7619 - iou_no_bg: 0.1615 - loss: 0.5459 - val_accuracy: 0.5254 - val_iou_no_bg: 0.0781 - val_loss: 0.6904\nEpoch 2/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8747 - iou_no_bg: 0.2954 - loss: 0.4099\nEpoch 2: val_iou_no_bg did not improve from 0.07807\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.8747 - iou_no_bg: 0.2956 - loss: 0.4097 - val_accuracy: 0.3293 - val_iou_no_bg: 0.0483 - val_loss: 0.7727\nEpoch 3/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8856 - iou_no_bg: 0.3437 - loss: 0.3727\nEpoch 3: val_iou_no_bg improved from 0.07807 to 0.14169, saving model to outputs/BiSeNetV2_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 71ms/step - accuracy: 0.8857 - iou_no_bg: 0.3439 - loss: 0.3725 - val_accuracy: 0.5559 - val_iou_no_bg: 0.1417 - val_loss: 0.6150\nEpoch 4/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9039 - iou_no_bg: 0.3953 - loss: 0.3324\nEpoch 4: val_iou_no_bg improved from 0.14169 to 0.38183, saving model to outputs/BiSeNetV2_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 71ms/step - accuracy: 0.9040 - iou_no_bg: 0.3952 - loss: 0.3324 - val_accuracy: 0.8857 - val_iou_no_bg: 0.3818 - val_loss: 0.3487\nEpoch 5/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9143 - iou_no_bg: 0.4196 - loss: 0.3172\nEpoch 5: val_iou_no_bg improved from 0.38183 to 0.40062, saving model to outputs/BiSeNetV2_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 70ms/step - accuracy: 0.9143 - iou_no_bg: 0.4195 - loss: 0.3173 - val_accuracy: 0.9179 - val_iou_no_bg: 0.4006 - val_loss: 0.3167\nEpoch 6/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9144 - iou_no_bg: 0.4247 - loss: 0.3143\nEpoch 6: val_iou_no_bg improved from 0.40062 to 0.43349, saving model to outputs/BiSeNetV2_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 70ms/step - accuracy: 0.9145 - iou_no_bg: 0.4249 - loss: 0.3142 - val_accuracy: 0.9008 - val_iou_no_bg: 0.4335 - val_loss: 0.3049\nEpoch 7/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9255 - iou_no_bg: 0.4382 - loss: 0.3045\nEpoch 7: val_iou_no_bg did not improve from 0.43349\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.9255 - iou_no_bg: 0.4381 - loss: 0.3046 - val_accuracy: 0.8688 - val_iou_no_bg: 0.3449 - val_loss: 0.3801\nEpoch 8/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9238 - iou_no_bg: 0.4389 - loss: 0.3047\nEpoch 8: val_iou_no_bg did not improve from 0.43349\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.9239 - iou_no_bg: 0.4389 - loss: 0.3046 - val_accuracy: 0.9228 - val_iou_no_bg: 0.3965 - val_loss: 0.3280\nEpoch 9/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9325 - iou_no_bg: 0.4383 - loss: 0.3030\nEpoch 9: val_iou_no_bg did not improve from 0.43349\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.9325 - iou_no_bg: 0.4383 - loss: 0.3030 - val_accuracy: 0.9175 - val_iou_no_bg: 0.4240 - val_loss: 0.3072\nEpoch 10/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9307 - iou_no_bg: 0.4450 - loss: 0.3017\nEpoch 10: val_iou_no_bg did not improve from 0.43349\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.9307 - iou_no_bg: 0.4450 - loss: 0.3016 - val_accuracy: 0.8515 - val_iou_no_bg: 0.3598 - val_loss: 0.3624\nEpoch 11/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9389 - iou_no_bg: 0.4673 - loss: 0.2839\nEpoch 11: val_iou_no_bg did not improve from 0.43349\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.9389 - iou_no_bg: 0.4670 - loss: 0.2841 - val_accuracy: 0.8741 - val_iou_no_bg: 0.3522 - val_loss: 0.3641\nEpoch 12/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9376 - iou_no_bg: 0.4591 - loss: 0.2885\nEpoch 12: val_iou_no_bg improved from 0.43349 to 0.47537, saving model to outputs/BiSeNetV2_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 71ms/step - accuracy: 0.9376 - iou_no_bg: 0.4591 - loss: 0.2885 - val_accuracy: 0.9530 - val_iou_no_bg: 0.4754 - val_loss: 0.2814\nEpoch 13/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9431 - iou_no_bg: 0.4532 - loss: 0.2896\nEpoch 13: val_iou_no_bg improved from 0.47537 to 0.50824, saving model to outputs/BiSeNetV2_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 70ms/step - accuracy: 0.9431 - iou_no_bg: 0.4534 - loss: 0.2895 - val_accuracy: 0.9567 - val_iou_no_bg: 0.5082 - val_loss: 0.2627\nEpoch 14/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9493 - iou_no_bg: 0.4657 - loss: 0.2806\nEpoch 14: val_iou_no_bg did not improve from 0.50824\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.9493 - iou_no_bg: 0.4659 - loss: 0.2806 - val_accuracy: 0.9404 - val_iou_no_bg: 0.4598 - val_loss: 0.2898\nEpoch 15/15\n\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9476 - iou_no_bg: 0.4597 - loss: 0.2858\nEpoch 15: val_iou_no_bg did not improve from 0.50824\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.9476 - iou_no_bg: 0.4599 - loss: 0.2857 - val_accuracy: 0.9293 - val_iou_no_bg: 0.4692 - val_loss: 0.2855\n📏 Evaluating BiSeNetV2 ...\n🖼️  Saved severity visualization: outputs/viz_with_severity_BiSeNetV2.png\n\n================ Model Comparison (by Val IoU no-bg) ================\n        Model  Val Loss  Val IoU(no-bg)  Val Acc  Test Loss  Test IoU(no-bg)  Test Acc\nDeepLabV3Plus  0.226142        0.544084 0.953061   0.242569         0.510508  0.948654\n    BiSeNetV2  0.262737        0.508240 0.956744   0.282621         0.465644  0.955638\n         UNet  0.270797        0.467705 0.936042   0.280668         0.448613  0.936650\n          FCN  0.286500        0.456401 0.913806   0.303303         0.424203  0.913569\n       SegNet  0.388670        0.332777 0.876524   0.404951         0.303270  0.876666\n\n💾 Saved: outputs/model_comparison.csv\n✅ Done in 4727.7s\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# =========================================================\n# Apple Leaf Segmentation - MULTI-MODEL COMPARISON\n# UNet_MobileNetV2 (pretrained, fine-tune), UNet, DeepLabV3+, FCN, SegNet, BiSeNetV2\n# Stronger loss (Weighted CE + Focal-Tversky), optional auto class weights\n# TTA inference + small post-processing\n# Visuals: (1) per-sample Image|GT|Pred with severity %, (2) 3-row grid like screenshot\n# =========================================================\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nos.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\nos.environ[\"TF_DISABLE_PROFILER\"] = \"1\"\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport pandas as pd\nimport time\nimport random\n\n# ============ Config ============\nBASE_DIR    = \"/kaggle/input/apple-dataset/ATLDSD\"   # <--- change if needed\nIMG_SIZE    = 256\nBATCH_SIZE  = 8\nEPOCHS      = 12\nSEED        = 2025\n\n# ==== Resume / Skip settings =====\nOUTDIR = \"outputs\"\nSKIP_TRAIN_IF_CKPT = True         # if checkpoint exists, skip training that model\nRUN_ONLY = None                    # e.g. ['UNet_MobileNetV2'] or None\nSTART_AT = None                    # e.g. 'FCN' to skip earlier models\n\n# ==== Training knobs ====\nAUTO_CLASS_WEIGHTS = True         # compute from Y_train (overrides CLASS_WEIGHTS)\nUSE_TTA_IN_VIZ     = True         # use test-time augmentation in visualization preds\n\nrandom.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n\nCLASS_NAMES = [\n    \"Background\",           # 0\n    \"Healthy\",              # 1\n    \"Brown spot\",           # 2\n    \"Alternaria leaf spot\", # 3\n    \"Gray spot\",            # 4\n    \"Rust\"                  # 5\n]\nNUM_CLASSES = len(CLASS_NAMES)\n\n# exact RGB colors -> class index\nCOLOR_MAP = {\n    (0,   0,   0): 0,   # Background\n    (128, 0,   0): 1,   # Healthy\n    (128, 0, 128): 2,   # Brown spot (purple)\n    (128,128,  0): 3,   # Alternaria (olive)\n    (0,   0, 128): 4,   # Gray (blue)\n    (0, 128,   0): 5,   # Rust (green)\n}\n# default weights (can be overridden by AUTO_CLASS_WEIGHTS)\nCLASS_WEIGHTS = tf.constant([0.25, 0.7, 1.1, 1.1, 1.1, 1.2], dtype=tf.float32)\n\n# augmentation knobs\nA_ROT90_PROB   = 0.75\nA_FLIP_H_PROB  = 0.5\nA_FLIP_V_PROB  = 0.5\nA_JITTER_PROB  = 0.6\nA_NOISE_PROB   = 0.3\nA_CROP_PROB    = 0.6\nCROP_MIN_FRAC  = 0.85\n\n# ============ Utils ============\ndef set_gpu_growth():\n    try:\n        gpus = tf.config.list_physical_devices('GPU')\n        if gpus:\n            for g in gpus:\n                tf.config.experimental.set_memory_growth(g, True)\n            print(f\"✅ GPU found: {len(gpus)}; memory growth enabled\")\n        else:\n            print(\"ℹ️  No GPU detected; running on CPU\")\n    except Exception as e:\n        print(\"⚠️  GPU mem-growth not set:\", e)\nset_gpu_growth()\n\ndef rgb_mask_to_classes(mask_rgb):\n    out = np.zeros(mask_rgb.shape[:2], dtype=np.uint8)\n    R, G, B = mask_rgb[...,0], mask_rgb[...,1], mask_rgb[...,2]\n    for (r,g,b), cls in COLOR_MAP.items():\n        m = (R == r) & (G == g) & (B == b)\n        out[m] = cls\n    return out\n\nPALETTE = {\n    0:(0,0,0), 1:(128,0,0), 2:(128,0,128), 3:(128,128,0), 4:(0,0,128), 5:(0,128,0)\n}\ndef mask_to_color(mask):\n    h,w = mask.shape\n    out = np.zeros((h,w,3), dtype=np.uint8)\n    for c, col in PALETTE.items():\n        out[mask==c] = col\n    return out\n\n# ===================== Severity Utils & Visualization =====================\ndef compute_severity_percentages(mask_int):\n    \"\"\"\n    Compute severity % per class with respect to LEAF area (non-background).\n    mask_int: [H,W] uint8 class map (0=background, 1=healthy, 2..=diseases)\n    Returns: (per_class_dict, healthy_pct, disease_total_pct)\n    \"\"\"\n    m = np.asarray(mask_int, dtype=np.uint8)\n    leaf = (m != 0)\n    leaf_pixels = int(leaf.sum())\n    if leaf_pixels == 0:\n        per_class = {CLASS_NAMES[c]: 0.0 for c in range(2, NUM_CLASSES)}\n        healthy_pct = 0.0\n        disease_total = 0.0\n        return per_class, healthy_pct, disease_total\n\n    per_class = {}\n    for c in range(2, NUM_CLASSES):\n        per_class[CLASS_NAMES[c]] = 100.0 * float((m == c).sum()) / leaf_pixels\n\n    healthy_pct = 100.0 * float((m == 1).sum()) / leaf_pixels\n    disease_total = 100.0 - healthy_pct\n    return per_class, healthy_pct, disease_total\n\ndef _box_text_from_severity(per_class, healthy_pct, disease_total):\n    lines = [f\"Healthy: {healthy_pct:5.1f}%\",\n             f\"Total disease: {disease_total:5.1f}%\"]\n    for name, pct in per_class.items():\n        lines.append(f\"{name}: {pct:5.1f}%\")\n    return \"\\n\".join(lines)\n\n# ---- TTA + tiny cleanup for nicer predictions (for visualization/presentations) ----\ndef predict_prob_tta(model, img):\n    \"\"\"Average probabilities over a few simple transforms, then invert them.\"\"\"\n    imgs = [\n        img,\n        np.flip(img, axis=1),                 # hflip\n        np.flip(img, axis=0),                 # vflip\n        np.rot90(img, k=1)\n    ]\n    probs = []\n    for im in imgs:\n        p = model.predict(im[None], verbose=0)[0]\n        probs.append(p)\n    # invert transforms\n    probs[1] = np.flip(probs[1], axis=1)\n    probs[2] = np.flip(probs[2], axis=0)\n    probs[3] = np.rot90(probs[3], k=3)\n    return np.mean(probs, axis=0)\n\ndef small_component_cleanup(mask, min_frac=0.001):\n    \"\"\"Remove tiny isolated blobs per class (send to 'Healthy').\"\"\"\n    H, W = mask.shape\n    min_area = max(1, int(H*W*min_frac))\n    out = mask.copy()\n    for c in range(1, NUM_CLASSES):\n        m = (out == c).astype(np.uint8)\n        if m.sum() == 0: \n            continue\n        num, labels = cv2.connectedComponents(m, connectivity=8)\n        for lab in range(1, num):\n            area = int((labels == lab).sum())\n            if area < min_area:\n                out[labels == lab] = 1\n    return out\n\ndef visualize_with_severity(model, Xv, Yv_int, n=4, outdir=\"outputs\", seed=2025):\n    \"\"\"\n    Show Image | GT | Pred with severity (%) boxes (n rows of triplets).\n    \"\"\"\n    np.random.seed(seed)\n    os.makedirs(outdir, exist_ok=True)\n    idx = np.random.choice(len(Xv), size=min(n, len(Xv)), replace=False)\n\n    fig, axs = plt.subplots(len(idx), 3, figsize=(11, 3.6*len(idx)))\n    if len(idx) == 1:\n        axs = np.expand_dims(axs, 0)\n\n    for r, i in enumerate(idx):\n        img = Xv[i]\n        gt  = Yv_int[i].astype(np.uint8)\n\n        # Predict (with optional TTA + cleanup)\n        if USE_TTA_IN_VIZ:\n            pr = predict_prob_tta(model, img)\n        else:\n            pr = model.predict(img[None], verbose=0)[0]\n        pm  = np.argmax(pr, axis=-1).astype(np.uint8)\n        pm  = small_component_cleanup(pm, min_frac=0.001)\n\n        # severities\n        gt_per, gt_healthy, gt_dis = compute_severity_percentages(gt)\n        pr_per, pr_healthy, pr_dis = compute_severity_percentages(pm)\n\n        axs[r,0].imshow(img); axs[r,0].set_title(\"Image\"); axs[r,0].axis('off')\n\n        axs[r,1].imshow(mask_to_color(gt)); axs[r,1].set_title(\"Ground Truth\"); axs[r,1].axis('off')\n        gt_txt = _box_text_from_severity(gt_per, gt_healthy, gt_dis)\n        axs[r,1].text(0.02, 0.98, gt_txt, transform=axs[r,1].transAxes,\n                      va='top', ha='left', fontsize=9,\n                      bbox=dict(facecolor='white', alpha=0.75, edgecolor='black', boxstyle='round,pad=0.4'))\n\n        axs[r,2].imshow(mask_to_color(pm)); axs[r,2].set_title(f\"Predicted ({model.name})\"); axs[r,2].axis('off')\n        pr_txt = _box_text_from_severity(pr_per, pr_healthy, pr_dis)\n        axs[r,2].text(0.02, 0.98, pr_txt, transform=axs[r,2].transAxes,\n                      va='top', ha='left', fontsize=9,\n                      bbox=dict(facecolor='white', alpha=0.75, edgecolor='black', boxstyle='round,pad=0.4'))\n\n    plt.tight_layout()\n    save_path = os.path.join(outdir, f\"viz_with_severity_{model.name}.png\")\n    plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.close()\n    print(f\"🖼️  Saved severity visualization: {save_path}\")\n    return save_path\n\ndef visualize_grid_with_severity(model, Xv, Yv_int, k=6, outdir=\"outputs\",\n                                 title=None, seed=2025):\n    \"\"\"\n    Make a 3-row panel like screenshot: [Images] / [GT] / [Pred], with severity % boxes.\n    k = number of columns (samples).\n    \"\"\"\n    np.random.seed(seed)\n    os.makedirs(outdir, exist_ok=True)\n    idx = np.random.choice(len(Xv), size=min(k, len(Xv)), replace=False)\n    cols = len(idx); rows = 3\n    fig, axs = plt.subplots(rows, cols, figsize=(cols*3.2, rows*3.2))\n    if cols == 1: axs = np.expand_dims(axs, 1)\n\n    for c, i in enumerate(idx):\n        img = Xv[i]; gt = Yv_int[i].astype(np.uint8)\n\n        if USE_TTA_IN_VIZ:\n            pr = predict_prob_tta(model, img)\n        else:\n            pr = model.predict(img[None], verbose=0)[0]\n        pm = np.argmax(pr, axis=-1).astype(np.uint8)\n        pm = small_component_cleanup(pm, min_frac=0.001)\n\n        # top: image\n        axs[0, c].imshow(img); axs[0, c].set_title(f\"Image {c+1}\", fontsize=11); axs[0, c].axis('off')\n\n        # middle: GT\n        axs[1, c].imshow(mask_to_color(gt)); axs[1, c].set_title(\"GT\", fontsize=10); axs[1, c].axis('off')\n        gt_per, gt_h, gt_d = compute_severity_percentages(gt)\n        axs[1, c].text(0.01, 0.99, _box_text_from_severity(gt_per, gt_h, gt_d),\n                       transform=axs[1, c].transAxes, va='top', ha='left', fontsize=8,\n                       bbox=dict(facecolor='white', alpha=0.78, edgecolor='black', boxstyle='round,pad=0.3'))\n\n        # bottom: Pred\n        axs[2, c].imshow(mask_to_color(pm)); axs[2, c].set_title(\"Pred\", fontsize=10); axs[2, c].axis('off')\n        pr_per, pr_h, pr_d = compute_severity_percentages(pm)\n        axs[2, c].text(0.01, 0.99, _box_text_from_severity(pr_per, pr_h, pr_d),\n                       transform=axs[2, c].transAxes, va='top', ha='left', fontsize=8,\n                       bbox=dict(facecolor='white', alpha=0.78, edgecolor='black', boxstyle='round,pad=0.3'))\n\n    if title is None:\n        title = f\"{model.name} — Dice+CE + Focal-Tversky, Augmented\"\n    fig.suptitle(title, fontsize=14)\n    plt.tight_layout(rect=[0, 0, 1, 0.95])\n    save_path = os.path.join(outdir, f\"panel_severity_{model.name}.png\")\n    plt.savefig(save_path, dpi=150, bbox_inches='tight'); plt.close()\n    print(f\"🖼️  Saved grid panel: {save_path}\")\n    return save_path\n\n# ============ Dataset ============\nclass AppleLeafDataset:\n    IMG_EXTS = (\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\")\n    def __init__(self, base_dir, image_size=256):\n        self.base_dir = base_dir\n        self.image_size = image_size\n        self.image_paths, self.mask_paths = self._discover_pairs()\n        print(f\"✅ Paired samples: {len(self.image_paths)}\")\n\n    def _list_images(self, d):\n        acc = []\n        for r,_,fs in os.walk(d):\n            for f in fs:\n                if f.lower().endswith(self.IMG_EXTS):\n                    acc.append(os.path.join(r,f))\n        return acc\n\n    def _discover_pairs(self):\n        imgs, msks = [], []\n        if not os.path.exists(self.base_dir):\n            raise FileNotFoundError(f\"Base dir not found: {self.base_dir}\")\n        for cls_folder in sorted(os.listdir(self.base_dir)):\n            cpath = os.path.join(self.base_dir, cls_folder)\n            if not os.path.isdir(cpath): continue\n            img_dir = os.path.join(cpath, \"image\")\n            msk_dir = os.path.join(cpath, \"label\")\n            if not (os.path.exists(img_dir) and os.path.exists(msk_dir)): continue\n\n            img_files = self._list_images(img_dir)\n            msk_files = self._list_images(msk_dir)\n            img_by = {os.path.splitext(os.path.basename(p))[0].lower(): p for p in img_files}\n            msk_by = {os.path.splitext(os.path.basename(p))[0].lower(): p for p in msk_files}\n            common = sorted(set(img_by) & set(msk_by))\n            print(f\"📂 {cls_folder:20} | imgs:{len(img_files):4d} | masks:{len(msk_files):4d} | paired:{len(common):4d}\")\n            for s in common: imgs.append(img_by[s]); msks.append(msk_by[s])\n        return imgs, msks\n\n    def load(self):\n        X, Y = [], []\n        for ip, mp in tqdm(list(zip(self.image_paths, self.mask_paths)), desc=\"Loading data\"):\n            img = cv2.imread(ip, cv2.IMREAD_COLOR)\n            if img is None: continue\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_AREA)\n            img = img.astype(np.float32)/255.0\n\n            msk = cv2.imread(mp, cv2.IMREAD_COLOR)\n            if msk is None: continue\n            msk = cv2.cvtColor(msk, cv2.COLOR_BGR2RGB)\n            msk = cv2.resize(msk, (self.image_size, self.image_size), interpolation=cv2.INTER_NEAREST)\n            msk = rgb_mask_to_classes(msk)\n\n            X.append(img); Y.append(msk)\n        return np.asarray(X, np.float32), np.asarray(Y, np.uint8)\n\n# ============ Augmentation (tf.data) ============\ndef augment_img_mask(img, mask):\n    img = tf.cast(img, tf.float32)\n    mask = tf.cast(mask, tf.int32)\n    mask_3d = tf.expand_dims(mask, axis=-1)\n\n    def apply_transform(transform_func, prob):\n        return tf.cond(\n            tf.random.uniform([]) < prob,\n            lambda: transform_func(img, mask_3d),\n            lambda: (img, mask_3d)\n        )\n\n    def rot90_transform(i, m):\n        k = tf.random.uniform([], 0, 4, dtype=tf.int32)\n        return tf.image.rot90(i, k), tf.image.rot90(m, k)\n\n    img, mask_3d = apply_transform(rot90_transform, A_ROT90_PROB)\n\n    def flip_h(i, m): return tf.image.flip_left_right(i), tf.image.flip_left_right(m)\n    def flip_v(i, m): return tf.image.flip_up_down(i), tf.image.flip_up_down(m)\n    img, mask_3d = apply_transform(flip_h, A_FLIP_H_PROB)\n    img, mask_3d = apply_transform(flip_v, A_FLIP_V_PROB)\n\n    def crop_transform(i, m):\n        shape = tf.shape(i)\n        h, w = shape[0], shape[1]\n        frac = tf.random.uniform([], CROP_MIN_FRAC, 1.0)\n        nh = tf.cast(tf.cast(h, tf.float32) * frac, tf.int32)\n        nw = tf.cast(tf.cast(w, tf.float32) * frac, tf.int32)\n        nh = tf.minimum(nh, h); nw = tf.minimum(nw, w)\n        max_y = tf.maximum(1, h - nh); max_x = tf.maximum(1, w - nw)\n        oy = tf.random.uniform([], 0, max_y, dtype=tf.int32)\n        ox = tf.random.uniform([], 0, max_x, dtype=tf.int32)\n        i_crop = tf.image.crop_to_bounding_box(i, oy, ox, nh, nw)\n        m_crop = tf.image.crop_to_bounding_box(m, oy, ox, nh, nw)\n\n        i_resized = tf.image.resize(i_crop, [h, w], method='bilinear')\n\n        m_crop_f = tf.cast(m_crop, tf.float32)\n        m_resized_f = tf.image.resize(m_crop_f, [h, w], method='nearest')\n        m_resized = tf.cast(tf.round(m_resized_f), tf.int32)\n\n        return i_resized, m_resized\n\n    img, mask_3d = apply_transform(crop_transform, A_CROP_PROB)\n\n    def apply_photometric(i):\n        if tf.random.uniform([]) < A_JITTER_PROB:\n            i = tf.image.random_brightness(i, 0.15)\n            i = tf.image.random_contrast(i, 0.8, 1.2)\n            i = tf.image.random_saturation(i, 0.8, 1.2)\n            i = tf.image.random_hue(i, 0.02)\n            i = tf.clip_by_value(i, 0.0, 1.0)\n        if tf.random.uniform([]) < A_NOISE_PROB:\n            noise = tf.random.normal(tf.shape(i), 0.0, 0.02, dtype=tf.float32)\n            i = tf.clip_by_value(i + noise, 0.0, 1.0)\n        return i\n\n    img = apply_photometric(img)\n    mask = tf.squeeze(mask_3d, axis=-1)\n    return img, mask\n\ndef one_hot(mask):\n    return tf.one_hot(tf.cast(mask, tf.int32), depth=NUM_CLASSES)\n\ndef make_dataset(X, Y, batch_size=8, shuffle=False, augment=False):\n    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n    if shuffle:\n        ds = ds.shuffle(min(len(X), 1024), reshuffle_each_iteration=True)\n    def process(img, mask):\n        img = tf.cast(img, tf.float32)\n        mask = tf.cast(mask, tf.int32)\n        if augment:\n            img, mask = augment_img_mask(img, mask)\n        return img, one_hot(mask)\n    return ds.map(process, num_parallel_calls=tf.data.AUTOTUNE)\\\n             .batch(batch_size)\\\n             .prefetch(tf.data.AUTOTUNE)\n\n# ============ Models ============\n\n# Pretrained U-Net with MobileNetV2 encoder (ImageNet) + fine-tune\ndef build_unet_mobilenetv2(input_shape, num_classes, train_encoder=False):\n    # model input (your pipeline gives [0,1])\n    inputs = keras.Input(shape=input_shape)\n    # MobileNetV2 expects [-1, 1]; do a lightweight, differentiable scaling\n    x_in = layers.Lambda(lambda t: t * 2.0 - 1.0, name=\"scale_to_mnv2\") (inputs)\n\n    # IMPORTANT: connect your tensor to the encoder using input_tensor=\n    base = tf.keras.applications.MobileNetV2(\n        input_tensor=x_in, include_top=False, weights=\"imagenet\"\n    )\n    base.trainable = train_encoder\n\n    # Skip tensors now belong to the SAME graph as `inputs`\n    s1 = base.get_layer('block_1_expand_relu').output   # 128x128\n    s2 = base.get_layer('block_3_expand_relu').output   # 64x64\n    s3 = base.get_layer('block_6_expand_relu').output   # 32x32\n    s4 = base.get_layer('block_13_expand_relu').output  # 16x16\n    bn = base.get_layer('block_16_project').output      # 8x8\n\n    def up_block(x, skip, f):\n        x = layers.Conv2DTranspose(f, 3, strides=2, padding='same')(x)\n        x = layers.Concatenate()([x, skip])\n        x = layers.Conv2D(f, 3, padding='same', activation='relu')(x); x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(f, 3, padding='same', activation='relu')(x); x = layers.BatchNormalization()(x)\n        return x\n\n    x = bn\n    x = up_block(x, s4, 256)   # 8->16\n    x = up_block(x, s3, 128)   # 16->32\n    x = up_block(x, s2, 64)    # 32->64\n    x = up_block(x, s1, 32)    # 64->128\n    x = layers.Conv2DTranspose(32, 3, strides=2, padding='same')(x)  # 128->256\n\n    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(x)\n    model = keras.Model(inputs, outputs, name=\"UNet_MobileNetV2\")\n    model._encoder = base  # keep handle for the fine-tuning phase\n    return model\n\n\n# 1) UNet (from scratch)\ndef build_unet(input_shape, num_classes, base=48, drop=0.15):\n    x_in = keras.Input(shape=input_shape)\n    def blk(x,f):\n        x = layers.Conv2D(f,3,padding='same',activation='relu')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(f,3,padding='same',activation='relu')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.SpatialDropout2D(drop)(x)\n        return x\n\n    c1 = blk(x_in, base);        p1 = layers.MaxPooling2D(2)(c1)      # 256->128\n    c2 = blk(p1, base*2);        p2 = layers.MaxPooling2D(2)(c2)      # 128->64\n    c3 = blk(p2, base*4);        p3 = layers.MaxPooling2D(2)(c3)      # 64->32\n    c4 = blk(p3, base*8);        p4 = layers.MaxPooling2D(2)(c4)      # 32->16\n    bn = blk(p4, base*16)\n\n    u6 = layers.Conv2DTranspose(base*8,2,2,padding='same')(bn)         # 16->32\n    u6 = layers.Concatenate()([u6,c4]); c6 = blk(u6, base*8)\n    u7 = layers.Conv2DTranspose(base*4,2,2,padding='same')(c6)         # 32->64\n    u7 = layers.Concatenate()([u7,c3]); c7 = blk(u7, base*4)\n    u8 = layers.Conv2DTranspose(base*2,2,2,padding='same')(c7)         # 64->128\n    u8 = layers.Concatenate()([u8,c2]); c8 = blk(u8, base*2)\n    u9 = layers.Conv2DTranspose(base,2,2,padding='same')(c8)           # 128->256\n    u9 = layers.Concatenate()([u9,c1]); c9 = blk(u9, base)\n\n    out = layers.Conv2D(num_classes,1,activation='softmax')(c9)\n    return keras.Model(x_in, out, name=\"UNet\")\n\n# 2) DeepLabV3+ (fixed pooling resize)\ndef build_deeplabv3plus(input_shape, num_classes):\n    def aspp(x):\n        dims = x.shape[-1]\n        h, w = x.shape[1], x.shape[2]  # ints for fixed input\n\n        pool = layers.GlobalAveragePooling2D()(x)\n        pool = layers.Reshape((1, 1, dims))(pool)\n        pool = layers.Conv2D(256, 1, activation='relu', padding='same')(pool)\n        pool = layers.BatchNormalization()(pool)\n        pool = layers.UpSampling2D(size=(h, w), interpolation='bilinear')(pool)\n\n        conv1 = layers.Conv2D(256, 1, activation='relu', padding='same')(x)\n        conv1 = layers.BatchNormalization()(conv1)\n\n        c6  = layers.Conv2D(256, 3, activation='relu', padding='same', dilation_rate=6)(x);  c6  = layers.BatchNormalization()(c6)\n        c12 = layers.Conv2D(256, 3, activation='relu', padding='same', dilation_rate=12)(x); c12 = layers.BatchNormalization()(c12)\n        c18 = layers.Conv2D(256, 3, activation='relu', padding='same', dilation_rate=18)(x); c18 = layers.BatchNormalization()(c18)\n\n        y = layers.Concatenate()([pool, conv1, c6, c12, c18])\n        y = layers.Conv2D(256, 1, activation='relu', padding='same')(y)\n        y = layers.BatchNormalization()(y)\n        return y\n\n    inputs = keras.Input(shape=input_shape)\n\n    x = layers.Conv2D(32, 3, strides=2, padding='same', activation='relu')(inputs)  # 256->128\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)                  # 128->128\n    x = layers.BatchNormalization()(x)\n    low = x\n\n    x = layers.Conv2D(128, 3, strides=2, padding='same', activation='relu')(x)      # 128->64\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)                 # 64->64\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv2D(512, 3, strides=2, padding='same', activation='relu')(x)      # 64->32\n    x = layers.BatchNormalization()(x)                                              # 32x32\n\n    x = aspp(x)                                                                     # 32x32\n    x = layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(x)               # 32->128\n    low = layers.Conv2D(48, 1, activation='relu', padding='same')(low); low = layers.BatchNormalization()(low)\n    x = layers.Concatenate()([x, low])                                              # 128\n    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x); x = layers.BatchNormalization()(x)\n    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)               # 128->256\n\n    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=\"DeepLabV3Plus\")\n\n# 3) FCN\ndef build_fcn(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(inputs)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x)\n    p1 = layers.MaxPooling2D(2)(x)   # 256->128\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(p1)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x)\n    p2 = layers.MaxPooling2D(2)(x)   # 128->64\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(p2)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x)\n    p3 = layers.MaxPooling2D(2)(x)   # 64->32\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(p3)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x)\n    p4 = layers.MaxPooling2D(2)(x)   # 32->16\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(p4)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x)\n    p5 = layers.MaxPooling2D(2)(x)   # 16->8\n\n    x = layers.Conv2D(4096,7,padding='same',activation='relu')(p5); x = layers.Dropout(0.5)(x)\n    x = layers.Conv2D(4096,1,activation='relu')(x); x = layers.Dropout(0.5)(x)\n\n    s5 = layers.Conv2D(num_classes,1)(x)\n    s4 = layers.Conv2D(num_classes,1)(p4)\n    s3 = layers.Conv2D(num_classes,1)(p3)\n\n    up2 = layers.Conv2DTranspose(num_classes,4,strides=2,padding='same')(s5)  # 8->16\n    f4  = layers.Add()([up2, s4])\n    up4 = layers.Conv2DTranspose(num_classes,4,strides=2,padding='same')(f4)  # 16->32\n    f3  = layers.Add()([up4, s3])\n    outputs = layers.Conv2DTranspose(num_classes,16,strides=8,padding='same',activation='softmax')(f3)  # 32->256\n    return keras.Model(inputs, outputs, name=\"FCN\")\n\n# 4) SegNet\ndef build_segnet(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(inputs); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x);     x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D(2)(x)  # 256->128\n\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D(2)(x)  # 128->64\n\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D(2)(x)  # 64->32\n\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D(2)(x)  # 32->16\n\n    x = layers.UpSampling2D(2)(x)  # 16->32\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n\n    x = layers.UpSampling2D(2)(x)  # 32->64\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n\n    x = layers.UpSampling2D(2)(x)  # 64->128\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n\n    x = layers.UpSampling2D(2)(x)  # 128->256\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n\n    outputs = layers.Conv2D(num_classes,1,activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=\"SegNet\")\n\n# 5) BiSeNetV2 (compact; main head only) — fixed ContextEmbedding (no Lambda)\ndef build_bisenetv2(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    def ConvBNReLU(x, f, k=3, s=1):\n        x = layers.Conv2D(f, k, strides=s, padding='same', use_bias=False)(x)\n        x = layers.BatchNormalization()(x)\n        return layers.ReLU()(x)\n    def DWConvBNReLU(x, k=3, s=1):\n        x = layers.DepthwiseConv2D(k, strides=s, padding='same', use_bias=False)(x)\n        x = layers.BatchNormalization()(x)\n        return layers.ReLU()(x)\n    def DetailBranch(x):\n        x = ConvBNReLU(x, 64, 3, 2); x = ConvBNReLU(x, 64, 3, 1); x = ConvBNReLU(x, 64, 3, 1)\n        x = ConvBNReLU(x, 64, 3, 2); x = ConvBNReLU(x, 64, 3, 1); x = ConvBNReLU(x, 64, 3, 1)\n        x = ConvBNReLU(x, 128, 3, 2); x = ConvBNReLU(x, 128, 3, 1); x = ConvBNReLU(x, 128, 3, 1)\n        return x  # /8\n    def StemBlock(x):\n        x = ConvBNReLU(x, 16, 3, 2); x = DWConvBNReLU(x, 3, 1); x = ConvBNReLU(x, 16, 1, 1)\n        x = ConvBNReLU(x, 32, 3, 2); x = DWConvBNReLU(x, 3, 1); x = ConvBNReLU(x, 32, 1, 1)\n        return x  # /4\n    def GEBlock(x, out_ch, stride):\n        in_ch = x.shape[-1]\n        y = DWConvBNReLU(x, 3, stride); y = ConvBNReLU(y, out_ch, 1, 1)\n        if stride == 1 and in_ch == out_ch: y = layers.Add()([x, y])\n        return y\n    def ContextEmbedding(x, ch=128):\n        h = layers.GlobalAveragePooling2D(keepdims=True)(x); h = layers.BatchNormalization()(h); h = ConvBNReLU(h, ch, 1, 1)\n        H = input_shape[0] // 16; W = input_shape[1] // 16\n        h = layers.UpSampling2D(size=(H, W), interpolation='bilinear')(h)\n        y = layers.Add()([x, h]); y = ConvBNReLU(y, ch, 3, 1)\n        return y\n    def SemanticBranch(x):\n        x = StemBlock(x); x = GEBlock(x, 64, 2); x = GEBlock(x, 64, 1)\n        x = GEBlock(x, 128, 2); x = GEBlock(x, 128, 1); x = GEBlock(x, 128, 1)\n        x = ContextEmbedding(x, 128); x = layers.UpSampling2D(size=2, interpolation='bilinear')(x)\n        return x\n    def FeatureFusion(detail, semantic, out_ch=256):\n        x = layers.Concatenate()([detail, semantic]); trunk = ConvBNReLU(x, out_ch, 3, 1)\n        att = layers.GlobalAveragePooling2D(keepdims=True)(trunk); att = ConvBNReLU(att, out_ch // 4, 1, 1)\n        att = layers.Conv2D(out_ch, 1, activation='sigmoid', padding='same')(att)\n        out = layers.Multiply()([trunk, att]); out = layers.Add()([trunk, out]); return out\n    def SegHead(x, num_classes, up_factor=8):\n        x = ConvBNReLU(x, 128, 3, 1); x = layers.Conv2D(num_classes, 1, padding='same', activation='softmax')(x)\n        x = layers.UpSampling2D(size=up_factor, interpolation='bilinear')(x); return x\n    db = DetailBranch(inputs); sb = SemanticBranch(inputs); fused = FeatureFusion(db, sb, out_ch=256)\n    outputs = SegHead(fused, num_classes, up_factor=8); return keras.Model(inputs, outputs, name=\"BiSeNetV2\")\n\n# ============ Loss and Metrics ============\nSMOOTH = 1e-6\n\ndef _resize_to_label(y_pred, y_true):\n    ph = tf.shape(y_pred)[1]; pw = tf.shape(y_pred)[2]\n    th = tf.shape(y_true)[1]; tw = tf.shape(y_true)[2]\n    need = tf.logical_or(tf.not_equal(ph, th), tf.not_equal(pw, tw))\n    def _do(): return tf.image.resize(y_pred, (th, tw), method='bilinear')\n    return tf.cond(need, _do, lambda: y_pred)\n\ndef weighted_ce(y_true, y_pred):\n    y_pred = _resize_to_label(y_pred, y_true)\n    w = tf.reduce_sum(CLASS_WEIGHTS * y_true, axis=-1)                 # [B,H,W]\n    ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)      # [B,H,W]\n    return tf.reduce_mean(ce * w)\n\ndef focal_tversky_loss(y_true, y_pred, alpha=0.7, beta=0.3, gamma=0.75, exclude_bg=True):\n    y_pred = _resize_to_label(y_pred, y_true)\n    if exclude_bg:\n        y_true = y_true[...,1:]; y_pred = y_pred[...,1:]\n    y_true_f = tf.reshape(y_true, [-1, tf.shape(y_true)[-1]])\n    y_pred_f = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])\n    tp = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n    fp = tf.reduce_sum((1. - y_true_f) * y_pred_f, axis=0)\n    fn = tf.reduce_sum(y_true_f * (1. - y_pred_f), axis=0)\n    t = (tp + SMOOTH) / (tp + alpha*fn + beta*fp + SMOOTH)\n    ft = tf.pow(1. - t, gamma)\n    return tf.reduce_mean(ft)\n\ndef combo_loss_stronger(y_true, y_pred, alpha=0.5):\n    return alpha * weighted_ce(y_true, y_pred) + (1.0 - alpha) * focal_tversky_loss(y_true, y_pred)\n\n@tf.function\ndef iou_no_bg(y_true, y_pred):\n    y_pred = _resize_to_label(y_pred, y_true)\n    y_true_cls = tf.argmax(y_true, axis=-1); y_pred_cls = tf.argmax(y_pred, axis=-1)\n    y_true_oh = tf.one_hot(y_true_cls, depth=NUM_CLASSES, dtype=tf.float32)\n    y_pred_oh = tf.one_hot(y_pred_cls, depth=NUM_CLASSES, dtype=tf.float32)\n    y_true_f = tf.reshape(y_true_oh, [-1, NUM_CLASSES]); y_pred_f = tf.reshape(y_pred_oh, [-1, NUM_CLASSES])\n    inter = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n    union = tf.reduce_sum(y_true_f + y_pred_f - y_true_f * y_pred_f, axis=0)\n    inter_nb = inter[1:]; union_nb = union[1:]\n    iou = tf.where(union_nb > 0.0, inter_nb / (union_nb + 1e-7), 0.0)\n    return tf.reduce_mean(iou)\n\n# ============ Training / Evaluation Helpers ============\ndef compile_model(model, lr=1e-3):\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=lr),\n        loss=combo_loss_stronger,\n        metrics=[iou_no_bg, 'accuracy']\n    )\n    return model\n\ndef plot_history(hist, title, outdir):\n    plt.figure(figsize=(10,4))\n    # loss\n    plt.subplot(1,2,1); plt.plot(hist.history['loss'], label='train')\n    if 'val_loss' in hist.history: plt.plot(hist.history['val_loss'], label='val')\n    plt.title(f'{title} - Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n    # IoU\n    if 'iou_no_bg' in hist.history:\n        plt.subplot(1,2,2); plt.plot(hist.history['iou_no_bg'], label='train IoU')\n        if 'val_iou_no_bg' in hist.history: plt.plot(hist.history['val_iou_no_bg'], label='val IoU')\n        plt.title(f'{title} - IoU(no-bg)'); plt.xlabel('Epoch'); plt.ylabel('IoU'); plt.legend()\n    plt.tight_layout(); os.makedirs(outdir, exist_ok=True)\n    p = os.path.join(outdir, f'{title}_curves.png')\n    plt.savefig(p, dpi=140, bbox_inches='tight'); plt.close()\n    return p\n\ndef compute_auto_class_weights(Y_int, num_classes):\n    counts = np.bincount(Y_int.flatten(), minlength=num_classes).astype(np.float64)\n    p = counts / max(1, counts.sum())\n    w = 1.0 / np.log(1.02 + p + 1e-12)  # inverse log frequency\n    w[0] = max(w[0]*0.5, 0.25)          # don't over-weight background\n    return w\n\n# ============ Main ============\ndef main():\n    t0 = time.time()\n    print(\"🔎 Loading dataset...\")\n    ds = AppleLeafDataset(BASE_DIR, IMG_SIZE)\n    X, Y = ds.load()\n\n    # simple split (≈70/15/15)\n    Xtr, Xte, Ytr, Yte = train_test_split(X, Y, test_size=0.15, random_state=SEED, shuffle=True)\n    Xtr, Xva, Ytr, Yva = train_test_split(Xtr, Ytr, test_size=0.1765, random_state=SEED, shuffle=True)\n\n    print(f\"Shapes -> Train: {Xtr.shape}, Val: {Xva.shape}, Test: {Xte.shape}\")\n\n    # Optional: auto class weights from train\n    if AUTO_CLASS_WEIGHTS:\n        global CLASS_WEIGHTS\n        CLASS_WEIGHTS = tf.constant(compute_auto_class_weights(Ytr, NUM_CLASSES), dtype=tf.float32)\n        print(\"Class weights (auto):\", CLASS_WEIGHTS.numpy())\n\n    train_ds = make_dataset(Xtr, Ytr, BATCH_SIZE, shuffle=True, augment=True)\n    val_ds   = make_dataset(Xva, Yva, BATCH_SIZE, shuffle=False, augment=False)\n    test_ds  = make_dataset(Xte, Yte, BATCH_SIZE, shuffle=False, augment=False)\n\n    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n\n    # Name -> builder (order preserved)\n    builders = {\n        'UNet_MobileNetV2': build_unet_mobilenetv2,   # pretrained + fine-tune\n        'UNet': build_unet,\n        'DeepLabV3Plus': build_deeplabv3plus,\n        'FCN': build_fcn,\n        'SegNet': build_segnet,\n        'BiSeNetV2': build_bisenetv2\n    }\n\n    # decide which to run\n    model_names = list(builders.keys())\n    if START_AT and START_AT in model_names:\n        model_names = model_names[model_names.index(START_AT):]\n    if RUN_ONLY:\n        model_names = [n for n in model_names if n in RUN_ONLY]\n\n    results = []\n    os.makedirs(OUTDIR, exist_ok=True)\n\n    for name in model_names:\n        tf.keras.backend.clear_session()\n        ckpt_path = os.path.join(OUTDIR, f\"{name}_best.keras\")\n\n        if SKIP_TRAIN_IF_CKPT and os.path.exists(ckpt_path):\n            print(f\"⏭️  {name}: checkpoint found -> skipping training, loading for eval\")\n            try:\n                model = keras.models.load_model(ckpt_path, compile=False)\n                compile_model(model, lr=1e-3)\n            except Exception as e:\n                print(f\"⚠️  Failed to load {name} checkpoint: {e}\")\n                print(f\"🔄 Re-training {name} instead...\")\n                model = builders[name](input_shape, NUM_CLASSES)\n                # standard single-phase training below\n                compile_model(model, lr=1e-3)\n                cbs = [\n                    keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_iou_no_bg', mode='max',\n                                                    save_best_only=True, save_weights_only=False, verbose=1),\n                    keras.callbacks.EarlyStopping(monitor='val_iou_no_bg', mode='max',\n                                                  patience=6, restore_best_weights=True),\n                    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3,\n                                                      min_lr=1e-5, verbose=1)\n                ]\n                hist = model.fit(train_ds, validation_data=val_ds,\n                                 epochs=EPOCHS, verbose=1, callbacks=cbs)\n                _ = plot_history(hist, name, OUTDIR)\n        else:\n            print(f\"\\n🚀 Training {name} ...\")\n            model = builders[name](input_shape, NUM_CLASSES)\n\n            if hasattr(model, \"_encoder\"):\n                # Phase 1: freeze encoder\n                model._encoder.trainable = False\n                compile_model(model, lr=1e-3)\n                hist1 = model.fit(train_ds, validation_data=val_ds, epochs=max(2, EPOCHS//2), verbose=1)\n                # Phase 2: unfreeze encoder and fine-tune with lower LR\n                model._encoder.trainable = True\n                compile_model(model, lr=3e-4)\n                cbs = [\n                    keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_iou_no_bg', mode='max',\n                                                    save_best_only=True, save_weights_only=False, verbose=1),\n                    keras.callbacks.EarlyStopping(monitor='val_iou_no_bg', mode='max',\n                                                  patience=6, restore_best_weights=True),\n                    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3,\n                                                      min_lr=1e-5, verbose=1)\n                ]\n                hist2 = model.fit(train_ds, validation_data=val_ds,\n                                  initial_epoch=max(2, EPOCHS//2), epochs=EPOCHS, verbose=1, callbacks=cbs)\n                _ = plot_history(hist2, name, OUTDIR)\n            else:\n                compile_model(model, lr=1e-3)\n                cbs = [\n                    keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_iou_no_bg', mode='max',\n                                                    save_best_only=True, save_weights_only=False, verbose=1),\n                    keras.callbacks.EarlyStopping(monitor='val_iou_no_bg', mode='max',\n                                                  patience=6, restore_best_weights=True),\n                    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3,\n                                                      min_lr=1e-5, verbose=1)\n                ]\n                hist = model.fit(train_ds, validation_data=val_ds,\n                                 epochs=EPOCHS, verbose=1, callbacks=cbs)\n                _ = plot_history(hist, name, OUTDIR)\n\n        # Evaluate\n        print(f\"📏 Evaluating {name} ...\")\n        val_metrics  = model.evaluate(val_ds,  verbose=0)\n        test_metrics = model.evaluate(test_ds, verbose=0)\n        res = {\n            \"Model\": name,\n            \"Val Loss\": float(val_metrics[0]),\n            \"Val IoU(no-bg)\": float(val_metrics[1]),\n            \"Val Acc\": float(val_metrics[2]),\n            \"Test Loss\": float(test_metrics[0]),\n            \"Test IoU(no-bg)\": float(test_metrics[1]),\n            \"Test Acc\": float(test_metrics[2]),\n        }\n        results.append(res)\n\n        # Visuals: single-sample rows + grid panel with severity %\n        _ = visualize_with_severity(model, Xva, Yva, n=4, outdir=OUTDIR)\n        _ = visualize_grid_with_severity(model, Xva, Yva, k=6, outdir=OUTDIR,\n                                         title=f\"{name} — Dice+CE + Focal-Tversky, Augmented\")\n\n    # Save/append comparison CSV\n    cmp_csv = os.path.join(OUTDIR, \"model_comparison.csv\")\n    df_new = pd.DataFrame(results)\n    if os.path.exists(cmp_csv):\n        try:\n            df_old = pd.read_csv(cmp_csv)\n            df = (pd.concat([df_old, df_new], ignore_index=True)\n                    .drop_duplicates(subset=['Model'], keep='last'))\n        except Exception:\n            df = df_new\n    else:\n        df = df_new\n    df = df.sort_values(\"Val IoU(no-bg)\", ascending=False)\n    df.to_csv(cmp_csv, index=False)\n    print(\"\\n================ Model Comparison (by Val IoU no-bg) ================\")\n    print(df.to_string(index=False))\n    print(f\"\\n💾 Saved: {cmp_csv}\")\n    print(f\"✅ Done in {time.time()-t0:.1f}s\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T06:31:33.716215Z","iopub.execute_input":"2025-08-31T06:31:33.716521Z","iopub.status.idle":"2025-08-31T06:40:43.659426Z","shell.execute_reply.started":"2025-08-31T06:31:33.716498Z","shell.execute_reply":"2025-08-31T06:40:43.658527Z"}},"outputs":[{"name":"stdout","text":"⚠️  GPU mem-growth not set: Physical devices cannot be modified after being initialized\n🔎 Loading dataset...\n📂 Alternaria leaf spot | imgs: 278 | masks: 278 | paired: 278\n📂 Brown spot           | imgs: 215 | masks: 215 | paired: 215\n📂 Gray spot            | imgs: 395 | masks: 395 | paired: 395\n📂 Healthy leaf         | imgs: 409 | masks: 409 | paired: 409\n📂 Rust                 | imgs: 344 | masks: 344 | paired: 344\n✅ Paired samples: 1641\n","output_type":"stream"},{"name":"stderr","text":"Loading data: 100%|██████████| 1641/1641 [00:22<00:00, 73.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Shapes -> Train: (1147, 256, 256, 3), Val: (247, 256, 256, 3), Test: (247, 256, 256, 3)\nClass weights (auto): [ 0.9594292  3.3929112 41.759647  48.69141   47.26587   37.653244 ]\n\n🚀 Training UNet_MobileNetV2 ...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/4198803968.py:415: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  base = tf.keras.applications.MobileNetV2(\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/6\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1756621955.780273      99 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1756621955.933191      99 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m143/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7091 - iou_no_bg: 0.1901 - loss: 1.5009","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1756621983.011304      98 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1756621983.155204      98 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7101 - iou_no_bg: 0.1905 - loss: 1.4982","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1756622005.574143      98 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1756622005.719288      98 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 288ms/step - accuracy: 0.7111 - iou_no_bg: 0.1909 - loss: 1.4956 - val_accuracy: 0.5633 - val_iou_no_bg: 0.0420 - val_loss: 4.5434\nEpoch 2/6\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 81ms/step - accuracy: 0.9323 - iou_no_bg: 0.3389 - loss: 0.7989 - val_accuracy: 0.9545 - val_iou_no_bg: 0.3683 - val_loss: 0.7648\nEpoch 3/6\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 81ms/step - accuracy: 0.9412 - iou_no_bg: 0.4042 - loss: 0.6354 - val_accuracy: 0.9561 - val_iou_no_bg: 0.4431 - val_loss: 0.5563\nEpoch 4/6\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 80ms/step - accuracy: 0.9484 - iou_no_bg: 0.4184 - loss: 0.5920 - val_accuracy: 0.9502 - val_iou_no_bg: 0.4218 - val_loss: 0.5043\nEpoch 5/6\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 80ms/step - accuracy: 0.9476 - iou_no_bg: 0.4232 - loss: 0.5871 - val_accuracy: 0.9550 - val_iou_no_bg: 0.4310 - val_loss: 0.5594\nEpoch 6/6\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 80ms/step - accuracy: 0.9601 - iou_no_bg: 0.4607 - loss: 0.4878 - val_accuracy: 0.9577 - val_iou_no_bg: 0.4609 - val_loss: 0.4835\nEpoch 7/12\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9461 - iou_no_bg: 0.4397 - loss: 0.5842\nEpoch 7: val_iou_no_bg improved from -inf to 0.48409, saving model to outputs/UNet_MobileNetV2_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 354ms/step - accuracy: 0.9462 - iou_no_bg: 0.4398 - loss: 0.5838 - val_accuracy: 0.9700 - val_iou_no_bg: 0.4841 - val_loss: 0.5470 - learning_rate: 3.0000e-04\nEpoch 8/12\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9679 - iou_no_bg: 0.4701 - loss: 0.4532\nEpoch 8: val_iou_no_bg improved from 0.48409 to 0.49696, saving model to outputs/UNet_MobileNetV2_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 122ms/step - accuracy: 0.9679 - iou_no_bg: 0.4702 - loss: 0.4532 - val_accuracy: 0.9785 - val_iou_no_bg: 0.4970 - val_loss: 0.5207 - learning_rate: 3.0000e-04\nEpoch 9/12\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9652 - iou_no_bg: 0.4861 - loss: 0.4507\nEpoch 9: val_iou_no_bg did not improve from 0.49696\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.9651 - iou_no_bg: 0.4861 - loss: 0.4509 - val_accuracy: 0.9274 - val_iou_no_bg: 0.3989 - val_loss: 0.5998 - learning_rate: 3.0000e-04\nEpoch 10/12\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9667 - iou_no_bg: 0.4874 - loss: 0.4603\nEpoch 10: val_iou_no_bg improved from 0.49696 to 0.52146, saving model to outputs/UNet_MobileNetV2_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 119ms/step - accuracy: 0.9667 - iou_no_bg: 0.4874 - loss: 0.4602 - val_accuracy: 0.9772 - val_iou_no_bg: 0.5215 - val_loss: 0.4764 - learning_rate: 3.0000e-04\nEpoch 11/12\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9688 - iou_no_bg: 0.5100 - loss: 0.4090\nEpoch 11: val_iou_no_bg improved from 0.52146 to 0.52546, saving model to outputs/UNet_MobileNetV2_best.keras\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 118ms/step - accuracy: 0.9689 - iou_no_bg: 0.5100 - loss: 0.4091 - val_accuracy: 0.9699 - val_iou_no_bg: 0.5255 - val_loss: 0.4630 - learning_rate: 3.0000e-04\nEpoch 12/12\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9708 - iou_no_bg: 0.4957 - loss: 0.4137\nEpoch 12: val_iou_no_bg did not improve from 0.52546\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 110ms/step - accuracy: 0.9708 - iou_no_bg: 0.4957 - loss: 0.4136 - val_accuracy: 0.9408 - val_iou_no_bg: 0.4148 - val_loss: 0.5670 - learning_rate: 3.0000e-04\n📏 Evaluating UNet_MobileNetV2 ...\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1756622291.892091      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1756622292.044274      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1756622292.176930      96 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"🖼️  Saved severity visualization: outputs/viz_with_severity_UNet_MobileNetV2.png\n🖼️  Saved grid panel: outputs/panel_severity_UNet_MobileNetV2.png\n⏭️  UNet: checkpoint found -> skipping training, loading for eval\n📏 Evaluating UNet ...\n🖼️  Saved severity visualization: outputs/viz_with_severity_UNet.png\n🖼️  Saved grid panel: outputs/panel_severity_UNet.png\n⏭️  DeepLabV3Plus: checkpoint found -> skipping training, loading for eval\n📏 Evaluating DeepLabV3Plus ...\n🖼️  Saved severity visualization: outputs/viz_with_severity_DeepLabV3Plus.png\n🖼️  Saved grid panel: outputs/panel_severity_DeepLabV3Plus.png\n⏭️  FCN: checkpoint found -> skipping training, loading for eval\n📏 Evaluating FCN ...\n🖼️  Saved severity visualization: outputs/viz_with_severity_FCN.png\n🖼️  Saved grid panel: outputs/panel_severity_FCN.png\n⏭️  SegNet: checkpoint found -> skipping training, loading for eval\n📏 Evaluating SegNet ...\n🖼️  Saved severity visualization: outputs/viz_with_severity_SegNet.png\n🖼️  Saved grid panel: outputs/panel_severity_SegNet.png\n⏭️  BiSeNetV2: checkpoint found -> skipping training, loading for eval\n📏 Evaluating BiSeNetV2 ...\n🖼️  Saved severity visualization: outputs/viz_with_severity_BiSeNetV2.png\n🖼️  Saved grid panel: outputs/panel_severity_BiSeNetV2.png\n\n================ Model Comparison (by Val IoU no-bg) ================\n           Model  Val Loss  Val IoU(no-bg)  Val Acc  Test Loss  Test IoU(no-bg)  Test Acc\n   DeepLabV3Plus  0.595483        0.544084 0.953061   0.610699         0.510508  0.948654\nUNet_MobileNetV2  0.462968        0.525461 0.969878   0.413875         0.515935  0.967437\n       BiSeNetV2  0.582485        0.508240 0.956744   0.618243         0.465644  0.955638\n            UNet  0.751521        0.467705 0.936042   0.734968         0.448613  0.936650\n             FCN  0.791912        0.456401 0.913806   0.732217         0.424203  0.913569\n          SegNet  1.096917        0.332777 0.876524   1.113148         0.303270  0.876666\n\n💾 Saved: outputs/model_comparison.csv\n✅ Done in 549.6s\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# =========================================================\n# Apple Leaf Segmentation — Lift IoU Accuracy\n# Strategies included:\n#  • Better loss: Weighted CE + Focal-Tversky (alpha=0.8, beta=0.2, gamma=0.9)\n#  • Auto class weights from train masks\n#  • Disease-aware oversampling for training\n#  • Larger input option (progressive-ready): set IMG_SIZE to 384/512 if you can\n#  • Strong pretrained model: U-Net with MobileNetV2 encoder (fine-tune in 2 phases)\n#  • Aug tweaks: allow tighter crops to zoom into lesions\n#  • Metrics: overall IoU(no-bg) + Disease-only mIoU for monitoring\n#  • Visuals: Image | GT | Pred + per-class severity percentages, and 3-row grid\n# =========================================================\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nos.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\nos.environ[\"TF_DISABLE_PROFILER\"] = \"1\"\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport pandas as pd\nimport time\nimport random\n\n# ============ Config ============\nBASE_DIR    = \"/kaggle/input/apple-dataset/ATLDSD\"   # <--- change if needed\nIMG_SIZE    = 256   # Try 384 or 512 for higher IoU if GPU allows\nBATCH_SIZE  = 8\nEPOCHS      = 40    # train longer for better convergence\nSEED        = 2025\n\nOUTDIR = \"outputs\"\nSKIP_TRAIN_IF_CKPT = True\nRUN_ONLY = ['UNet_MobileNetV2']   # focus on the strongest model first\nSTART_AT = None\n\n# Training knobs\nAUTO_CLASS_WEIGHTS    = True   # infer from Y_train\nUSE_TTA_IN_VIZ        = True   # nicer visuals; eval uses built-in metrics\nOVERSAMPLE_DISEASE    = True   # oversample disease-rich images in train\nTOLERANT_LABEL_COLORS = True   # handle slight RGB variations in masks\n\nrandom.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n\nCLASS_NAMES = [\n    \"Background\",           # 0\n    \"Healthy\",              # 1\n    \"Brown spot\",           # 2\n    \"Alternaria leaf spot\", # 3\n    \"Gray spot\",            # 4\n    \"Rust\"                  # 5\n]\nNUM_CLASSES = len(CLASS_NAMES)\n\nCOLOR_MAP = {\n    (0,   0,   0): 0,   # Background\n    (128, 0,   0): 1,   # Healthy\n    (128, 0, 128): 2,   # Brown spot\n    (128,128,  0): 3,   # Alternaria\n    (0,   0, 128): 4,   # Gray\n    (0, 128,   0): 5,   # Rust\n}\n\n# default weights (overridden if AUTO_CLASS_WEIGHTS)\nCLASS_WEIGHTS = tf.constant([0.25, 0.7, 1.1, 1.1, 1.1, 1.2], dtype=tf.float32)\n\n# Augmentation knobs (more zoom-in to highlight lesions)\nA_ROT90_PROB   = 0.75\nA_FLIP_H_PROB  = 0.5\nA_FLIP_V_PROB  = 0.5\nA_JITTER_PROB  = 0.6\nA_NOISE_PROB   = 0.3\nA_CROP_PROB    = 0.7\nCROP_MIN_FRAC  = 0.65   # was 0.85 -> more aggressive zooms\n\n# ============ Utils ============\ndef set_gpu_growth():\n    try:\n        gpus = tf.config.list_physical_devices('GPU')\n        if gpus:\n            for g in gpus:\n                tf.config.experimental.set_memory_growth(g, True)\n            print(f\"✅ GPU found: {len(gpus)}; memory growth enabled\")\n        else:\n            print(\"ℹ️  No GPU detected; running on CPU\")\n    except Exception as e:\n        print(\"⚠️  GPU mem-growth not set:\", e)\nset_gpu_growth()\n\ndef rgb_mask_to_classes(mask_rgb, tol=10):\n    \"\"\"\n    Map RGB to class ids; if TOLERANT_LABEL_COLORS=True, allow a tolerance on RGB values.\n    \"\"\"\n    if not TOLERANT_LABEL_COLORS:\n        out = np.zeros(mask_rgb.shape[:2], dtype=np.uint8)\n        R, G, B = mask_rgb[...,0], mask_rgb[...,1], mask_rgb[...,2]\n        for (r,g,b), cls in COLOR_MAP.items():\n            m = (R == r) & (G == g) & (B == b)\n            out[m] = cls\n        return out\n    else:\n        out = np.zeros(mask_rgb.shape[:2], dtype=np.uint8)\n        for (r,g,b), cls in COLOR_MAP.items():\n            diff = np.abs(mask_rgb - np.array([r,g,b], np.uint8))\n            m = (diff[...,0] <= tol) & (diff[...,1] <= tol) & (diff[...,2] <= tol)\n            out[m] = cls\n        return out\n\nPALETTE = {\n    0:(0,0,0), 1:(128,0,0), 2:(128,0,128), 3:(128,128,0), 4:(0,0,128), 5:(0,128,0)\n}\ndef mask_to_color(mask):\n    h,w = mask.shape\n    out = np.zeros((h,w,3), dtype=np.uint8)\n    for c, col in PALETTE.items():\n        out[mask==c] = col\n    return out\n\n# ===================== Severity Utils & Visualization =====================\ndef compute_severity_percentages(mask_int):\n    m = np.asarray(mask_int, dtype=np.uint8)\n    leaf = (m != 0)\n    leaf_pixels = int(leaf.sum())\n    if leaf_pixels == 0:\n        per_class = {CLASS_NAMES[c]: 0.0 for c in range(2, NUM_CLASSES)}\n        healthy_pct = 0.0\n        disease_total = 0.0\n        return per_class, healthy_pct, disease_total\n\n    per_class = {}\n    for c in range(2, NUM_CLASSES):\n        per_class[CLASS_NAMES[c]] = 100.0 * float((m == c).sum()) / leaf_pixels\n    healthy_pct = 100.0 * float((m == 1).sum()) / leaf_pixels\n    disease_total = 100.0 - healthy_pct\n    return per_class, healthy_pct, disease_total\n\ndef _box_text_from_severity(per_class, healthy_pct, disease_total):\n    lines = [f\"Healthy: {healthy_pct:5.1f}%\",\n             f\"Total disease: {disease_total:5.1f}%\"]\n    for name, pct in per_class.items():\n        lines.append(f\"{name}: {pct:5.1f}%\")\n    return \"\\n\".join(lines)\n\ndef predict_prob_tta(model, img):\n    imgs = [img,\n            np.flip(img, axis=1),\n            np.flip(img, axis=0),\n            np.rot90(img, k=1)]\n    probs = []\n    for im in imgs:\n        p = model.predict(im[None], verbose=0)[0]\n        probs.append(p)\n    probs[1] = np.flip(probs[1], axis=1)\n    probs[2] = np.flip(probs[2], axis=0)\n    probs[3] = np.rot90(probs[3], k=3)\n    return np.mean(probs, axis=0)\n\ndef small_component_cleanup(mask, min_frac=0.001):\n    H, W = mask.shape\n    min_area = max(1, int(H*W*min_frac))\n    out = mask.copy()\n    for c in range(1, NUM_CLASSES):\n        m = (out == c).astype(np.uint8)\n        if m.sum() == 0: continue\n        num, labels = cv2.connectedComponents(m, connectivity=8)\n        for lab in range(1, num):\n            area = int((labels == lab).sum())\n            if area < min_area:\n                out[labels == lab] = 1  # send tiny islands to 'Healthy'\n    return out\n\ndef visualize_with_severity(model, Xv, Yv_int, n=4, outdir=\"outputs\", seed=2025):\n    np.random.seed(seed)\n    os.makedirs(outdir, exist_ok=True)\n    idx = np.random.choice(len(Xv), size=min(n, len(Xv)), replace=False)\n    fig, axs = plt.subplots(len(idx), 3, figsize=(11, 3.6*len(idx)))\n    if len(idx) == 1: axs = np.expand_dims(axs, 0)\n\n    for r, i in enumerate(idx):\n        img = Xv[i]\n        gt  = Yv_int[i].astype(np.uint8)\n        pr  = predict_prob_tta(model, img) if USE_TTA_IN_VIZ else model.predict(img[None], verbose=0)[0]\n        pm  = np.argmax(pr, axis=-1).astype(np.uint8)\n        pm  = small_component_cleanup(pm, min_frac=0.001)\n\n        gt_per, gt_h, gt_d = compute_severity_percentages(gt)\n        pr_per, pr_h, pr_d = compute_severity_percentages(pm)\n\n        axs[r,0].imshow(img); axs[r,0].set_title(\"Image\"); axs[r,0].axis('off')\n\n        axs[r,1].imshow(mask_to_color(gt)); axs[r,1].set_title(\"Ground Truth\"); axs[r,1].axis('off')\n        axs[r,1].text(0.02, 0.98, _box_text_from_severity(gt_per, gt_h, gt_d),\n                      transform=axs[r,1].transAxes, va='top', ha='left', fontsize=9,\n                      bbox=dict(facecolor='white', alpha=0.75, edgecolor='black', boxstyle='round,pad=0.4'))\n\n        axs[r,2].imshow(mask_to_color(pm)); axs[r,2].set_title(f\"Predicted ({model.name})\"); axs[r,2].axis('off')\n        axs[r,2].text(0.02, 0.98, _box_text_from_severity(pr_per, pr_h, pr_d),\n                      transform=axs[r,2].transAxes, va='top', ha='left', fontsize=9,\n                      bbox=dict(facecolor='white', alpha=0.75, edgecolor='black', boxstyle='round,pad=0.4'))\n    plt.tight_layout()\n    p = os.path.join(outdir, f\"viz_with_severity_{model.name}.png\")\n    plt.savefig(p, dpi=150, bbox_inches='tight'); plt.close()\n    print(f\"🖼️  Saved severity visualization: {p}\")\n    return p\n\ndef visualize_grid_with_severity(model, Xv, Yv_int, k=6, outdir=\"outputs\",\n                                 title=None, seed=2025):\n    np.random.seed(seed)\n    os.makedirs(outdir, exist_ok=True)\n    idx = np.random.choice(len(Xv), size=min(k, len(Xv)), replace=False)\n    cols = len(idx); rows = 3\n    fig, axs = plt.subplots(rows, cols, figsize=(cols*3.2, rows*3.2))\n    if cols == 1: axs = np.expand_dims(axs, 1)\n\n    for c, i in enumerate(idx):\n        img = Xv[i]; gt = Yv_int[i].astype(np.uint8)\n        pr = predict_prob_tta(model, img) if USE_TTA_IN_VIZ else model.predict(img[None], verbose=0)[0]\n        pm = np.argmax(pr, axis=-1).astype(np.uint8)\n        pm = small_component_cleanup(pm, min_frac=0.001)\n\n        axs[0, c].imshow(img); axs[0, c].set_title(f\"Image {c+1}\", fontsize=11); axs[0, c].axis('off')\n\n        axs[1, c].imshow(mask_to_color(gt)); axs[1, c].set_title(\"GT\", fontsize=10); axs[1, c].axis('off')\n        gt_per, gt_h, gt_d = compute_severity_percentages(gt)\n        axs[1, c].text(0.01, 0.99, _box_text_from_severity(gt_per, gt_h, gt_d),\n                       transform=axs[1, c].transAxes, va='top', ha='left', fontsize=8,\n                       bbox=dict(facecolor='white', alpha=0.78, edgecolor='black', boxstyle='round,pad=0.3'))\n\n        axs[2, c].imshow(mask_to_color(pm)); axs[2, c].set_title(\"Pred\", fontsize=10); axs[2, c].axis('off')\n        pr_per, pr_h, pr_d = compute_severity_percentages(pm)\n        axs[2, c].text(0.01, 0.99, _box_text_from_severity(pr_per, pr_h, pr_d),\n                       transform=axs[2, c].transAxes, va='top', ha='left', fontsize=8,\n                       bbox=dict(facecolor='white', alpha=0.78, edgecolor='black', boxstyle='round,pad=0.3'))\n    if title is None:\n        title = f\"{model.name} — WeightedCE + Focal-Tversky\"\n    fig.suptitle(title, fontsize=14)\n    plt.tight_layout(rect=[0, 0, 1, 0.95])\n    p = os.path.join(outdir, f\"panel_severity_{model.name}.png\")\n    plt.savefig(p, dpi=150, bbox_inches='tight'); plt.close()\n    print(f\"🖼️  Saved grid panel: {p}\")\n    return p\n\n# ============ Dataset ============\nclass AppleLeafDataset:\n    IMG_EXTS = (\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\")\n    def __init__(self, base_dir, image_size=256):\n        self.base_dir = base_dir\n        self.image_size = image_size\n        self.image_paths, self.mask_paths = self._discover_pairs()\n        print(f\"✅ Paired samples: {len(self.image_paths)}\")\n\n    def _list_images(self, d):\n        acc = []\n        for r,_,fs in os.walk(d):\n            for f in fs:\n                if f.lower().endswith(self.IMG_EXTS):\n                    acc.append(os.path.join(r,f))\n        return acc\n\n    def _discover_pairs(self):\n        imgs, msks = [], []\n        if not os.path.exists(self.base_dir):\n            raise FileNotFoundError(f\"Base dir not found: {self.base_dir}\")\n        for cls_folder in sorted(os.listdir(self.base_dir)):\n            cpath = os.path.join(self.base_dir, cls_folder)\n            if not os.path.isdir(cpath): continue\n            img_dir = os.path.join(cpath, \"image\")\n            msk_dir = os.path.join(cpath, \"label\")\n            if not (os.path.exists(img_dir) and os.path.exists(msk_dir)): continue\n\n            img_files = self._list_images(img_dir)\n            msk_files = self._list_images(msk_dir)\n            img_by = {os.path.splitext(os.path.basename(p))[0].lower(): p for p in img_files}\n            msk_by = {os.path.splitext(os.path.basename(p))[0].lower(): p for p in msk_files}\n            common = sorted(set(img_by) & set(msk_by))\n            print(f\"📂 {cls_folder:20} | imgs:{len(img_files):4d} | masks:{len(msk_files):4d} | paired:{len(common):4d}\")\n            for s in common: imgs.append(img_by[s]); msks.append(msk_by[s])\n        return imgs, msks\n\n    def load(self):\n        X, Y = [], []\n        for ip, mp in tqdm(list(zip(self.image_paths, self.mask_paths)), desc=\"Loading data\"):\n            img = cv2.imread(ip, cv2.IMREAD_COLOR)\n            if img is None: continue\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_AREA)\n            img = img.astype(np.float32)/255.0\n\n            msk = cv2.imread(mp, cv2.IMREAD_COLOR)\n            if msk is None: continue\n            msk = cv2.cvtColor(msk, cv2.COLOR_BGR2RGB)\n            msk = cv2.resize(msk, (self.image_size, self.image_size), interpolation=cv2.INTER_NEAREST)\n            msk = rgb_mask_to_classes(msk)\n\n            X.append(img); Y.append(msk)\n        return np.asarray(X, np.float32), np.asarray(Y, np.uint8)\n\n# ============ Augmentation (tf.data) ============\ndef augment_img_mask(img, mask):\n    img = tf.cast(img, tf.float32)\n    mask = tf.cast(mask, tf.int32)\n    mask_3d = tf.expand_dims(mask, axis=-1)\n\n    def apply_transform(transform_func, prob):\n        return tf.cond(\n            tf.random.uniform([]) < prob,\n            lambda: transform_func(img, mask_3d),\n            lambda: (img, mask_3d)\n        )\n\n    def rot90_transform(i, m):\n        k = tf.random.uniform([], 0, 4, dtype=tf.int32)\n        return tf.image.rot90(i, k), tf.image.rot90(m, k)\n    img, mask_3d = apply_transform(rot90_transform, A_ROT90_PROB)\n\n    def flip_h(i, m): return tf.image.flip_left_right(i), tf.image.flip_left_right(m)\n    def flip_v(i, m): return tf.image.flip_up_down(i), tf.image.flip_up_down(m)\n    img, mask_3d = apply_transform(flip_h, A_FLIP_H_PROB)\n    img, mask_3d = apply_transform(flip_v, A_FLIP_V_PROB)\n\n    def crop_transform(i, m):\n        shape = tf.shape(i)\n        h, w = shape[0], shape[1]\n        frac = tf.random.uniform([], CROP_MIN_FRAC, 1.0)\n        nh = tf.cast(tf.cast(h, tf.float32) * frac, tf.int32)\n        nw = tf.cast(tf.cast(w, tf.float32) * frac, tf.int32)\n        nh = tf.minimum(nh, h); nw = tf.minimum(nw, w)\n        max_y = tf.maximum(1, h - nh); max_x = tf.maximum(1, w - nw)\n        oy = tf.random.uniform([], 0, max_y, dtype=tf.int32)\n        ox = tf.random.uniform([], 0, max_x, dtype=tf.int32)\n        i_crop = tf.image.crop_to_bounding_box(i, oy, ox, nh, nw)\n        m_crop = tf.image.crop_to_bounding_box(m, oy, ox, nh, nw)\n\n        i_resized = tf.image.resize(i_crop, [h, w], method='bilinear')\n        m_crop_f = tf.cast(m_crop, tf.float32)\n        m_resized_f = tf.image.resize(m_crop_f, [h, w], method='nearest')\n        m_resized = tf.cast(tf.round(m_resized_f), tf.int32)\n        return i_resized, m_resized\n\n    img, mask_3d = apply_transform(crop_transform, A_CROP_PROB)\n\n    def apply_photometric(i):\n        if tf.random.uniform([]) < A_JITTER_PROB:\n            i = tf.image.random_brightness(i, 0.15)\n            i = tf.image.random_contrast(i, 0.8, 1.2)\n            i = tf.image.random_saturation(i, 0.8, 1.2)\n            i = tf.image.random_hue(i, 0.02)\n            i = tf.clip_by_value(i, 0.0, 1.0)\n        if tf.random.uniform([]) < A_NOISE_PROB:\n            noise = tf.random.normal(tf.shape(i), 0.0, 0.02, dtype=tf.float32)\n            i = tf.clip_by_value(i + noise, 0.0, 1.0)\n        return i\n\n    img = apply_photometric(img)\n    mask = tf.squeeze(mask_3d, axis=-1)\n    return img, mask\n\ndef one_hot(mask):\n    return tf.one_hot(tf.cast(mask, tf.int32), depth=NUM_CLASSES)\n\ndef make_dataset(X, Y, batch_size=8, shuffle=False, augment=False):\n    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n    if shuffle:\n        ds = ds.shuffle(min(len(X), 1024), reshuffle_each_iteration=True)\n    def process(img, mask):\n        img = tf.cast(img, tf.float32)\n        mask = tf.cast(mask, tf.int32)\n        if augment:\n            img, mask = augment_img_mask(img, mask)\n        return img, one_hot(mask)\n    return ds.map(process, num_parallel_calls=tf.data.AUTOTUNE)\\\n             .batch(batch_size)\\\n             .prefetch(tf.data.AUTOTUNE)\n\n# Disease-aware oversampling (static per run; simple & effective)\ndef disease_weight_per_sample(Y):\n    w = []\n    for m in Y:\n        leaf = (m != 0)\n        dz   = (m >= 2)\n        frac = float(dz.sum()) / max(1, int(leaf.sum()))\n        w.append(0.2 + 0.8*min(1.0, frac*10))  # boost images with more lesions\n    w = np.asarray(w, np.float64)\n    w = w / w.sum()\n    return w\n\ndef make_weighted_train_ds(X, Y, batch_size=8, augment=True):\n    p = disease_weight_per_sample(Y)\n    idx = np.random.choice(len(X), size=len(X), replace=True, p=p)\n    return make_dataset(X[idx], Y[idx], batch_size, shuffle=True, augment=augment)\n\n# ============ Models ============\n\n# Pretrained U-Net with MobileNetV2 encoder (ImageNet) + fine-tune\ndef build_unet_mobilenetv2(input_shape, num_classes, train_encoder=False):\n    inputs = keras.Input(shape=input_shape)\n    x_in = layers.Lambda(lambda t: t*2.0 - 1.0, name=\"scale_to_mnv2\")(inputs)  # [0,1]->[-1,1]\n    base = tf.keras.applications.MobileNetV2(\n        input_tensor=x_in, include_top=False, weights=\"imagenet\"\n    )\n    base.trainable = train_encoder\n\n    s1 = base.get_layer('block_1_expand_relu').output   # 128x128\n    s2 = base.get_layer('block_3_expand_relu').output   # 64x64\n    s3 = base.get_layer('block_6_expand_relu').output   # 32x32\n    s4 = base.get_layer('block_13_expand_relu').output  # 16x16\n    bn = base.get_layer('block_16_project').output      # 8x8\n\n    def up_block(x, skip, f):\n        x = layers.Conv2DTranspose(f, 3, strides=2, padding='same')(x)\n        x = layers.Concatenate()([x, skip])\n        x = layers.Conv2D(f, 3, padding='same', activation='relu')(x); x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(f, 3, padding='same', activation='relu')(x); x = layers.BatchNormalization()(x)\n        return x\n\n    x = bn\n    x = up_block(x, s4, 256)  # 8->16\n    x = up_block(x, s3, 128)  # 16->32\n    x = up_block(x, s2, 64)   # 32->64\n    x = up_block(x, s1, 32)   # 64->128\n    x = layers.Conv2DTranspose(32, 3, strides=2, padding='same')(x)  # 128->256\n    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(x)\n\n    model = keras.Model(inputs, outputs, name=\"UNet_MobileNetV2\")\n    model._encoder = base\n    return model\n\n# UNet (scratch)\ndef build_unet(input_shape, num_classes, base=48, drop=0.15):\n    x_in = keras.Input(shape=input_shape)\n    def blk(x,f):\n        x = layers.Conv2D(f,3,padding='same',activation='relu')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(f,3,padding='same',activation='relu')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.SpatialDropout2D(drop)(x)\n        return x\n    c1 = blk(x_in, base);        p1 = layers.MaxPooling2D(2)(c1)\n    c2 = blk(p1, base*2);        p2 = layers.MaxPooling2D(2)(c2)\n    c3 = blk(p2, base*4);        p3 = layers.MaxPooling2D(2)(c3)\n    c4 = blk(p3, base*8);        p4 = layers.MaxPooling2D(2)(c4)\n    bn = blk(p4, base*16)\n    u6 = layers.Conv2DTranspose(base*8,2,2,padding='same')(bn); u6 = layers.Concatenate()([u6,c4]); c6 = blk(u6, base*8)\n    u7 = layers.Conv2DTranspose(base*4,2,2,padding='same')(c6); u7 = layers.Concatenate()([u7,c3]); c7 = blk(u7, base*4)\n    u8 = layers.Conv2DTranspose(base*2,2,2,padding='same')(c7); u8 = layers.Concatenate()([u8,c2]); c8 = blk(u8, base*2)\n    u9 = layers.Conv2DTranspose(base,2,2,padding='same')(c8);   u9 = layers.Concatenate()([u9,c1]); c9 = blk(u9, base)\n    out = layers.Conv2D(num_classes,1,activation='softmax')(c9)\n    return keras.Model(x_in, out, name=\"UNet\")\n\n# DeepLabV3+ (light backbone)\ndef build_deeplabv3plus(input_shape, num_classes):\n    def aspp(x):\n        dims = x.shape[-1]; h, w = x.shape[1], x.shape[2]\n        pool = layers.GlobalAveragePooling2D()(x); pool = layers.Reshape((1,1,dims))(pool)\n        pool = layers.Conv2D(256,1,activation='relu',padding='same')(pool); pool = layers.BatchNormalization()(pool)\n        pool = layers.UpSampling2D(size=(h,w), interpolation='bilinear')(pool)\n        conv1 = layers.Conv2D(256,1,activation='relu',padding='same')(x); conv1 = layers.BatchNormalization()(conv1)\n        c6  = layers.Conv2D(256,3,activation='relu',padding='same',dilation_rate=6)(x);  c6  = layers.BatchNormalization()(c6)\n        c12 = layers.Conv2D(256,3,activation='relu',padding='same',dilation_rate=12)(x); c12 = layers.BatchNormalization()(c12)\n        c18 = layers.Conv2D(256,3,activation='relu',padding='same',dilation_rate=18)(x); c18 = layers.BatchNormalization()(c18)\n        y = layers.Concatenate()([pool, conv1, c6, c12, c18])\n        y = layers.Conv2D(256,1,activation='relu',padding='same')(y); y = layers.BatchNormalization()(y)\n        return y\n    inputs = keras.Input(shape=input_shape)\n    x = layers.Conv2D(32, 3, strides=2, padding='same', activation='relu')(inputs); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x); x = layers.BatchNormalization()(x)\n    low = x\n    x = layers.Conv2D(128, 3, strides=2, padding='same', activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512, 3, strides=2, padding='same', activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = aspp(x)\n    x = layers.UpSampling2D(size=(4,4), interpolation='bilinear')(x)\n    low = layers.Conv2D(48,1,activation='relu',padding='same')(low); low = layers.BatchNormalization()(low)\n    x = layers.Concatenate()([x, low])\n    x = layers.Conv2D(256,3,activation='relu',padding='same')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,activation='relu',padding='same')(x); x = layers.BatchNormalization()(x)\n    x = layers.UpSampling2D(size=(2,2), interpolation='bilinear')(x)\n    outputs = layers.Conv2D(num_classes,1,activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=\"DeepLabV3Plus\")\n\n# FCN\ndef build_fcn(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(inputs)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x); p1 = layers.MaxPooling2D(2)(x)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(p1)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); p2 = layers.MaxPooling2D(2)(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(p2)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x);  p3 = layers.MaxPooling2D(2)(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(p3)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x);  p4 = layers.MaxPooling2D(2)(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(p4)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x);  p5 = layers.MaxPooling2D(2)(x)\n    x = layers.Conv2D(4096,7,padding='same',activation='relu')(p5); x = layers.Dropout(0.5)(x)\n    x = layers.Conv2D(4096,1,activation='relu')(x); x = layers.Dropout(0.5)(x)\n    s5 = layers.Conv2D(num_classes,1)(x); s4 = layers.Conv2D(num_classes,1)(p4); s3 = layers.Conv2D(num_classes,1)(p3)\n    up2 = layers.Conv2DTranspose(num_classes,4,strides=2,padding='same')(s5);  f4 = layers.Add()([up2, s4])\n    up4 = layers.Conv2DTranspose(num_classes,4,strides=2,padding='same')(f4);  f3 = layers.Add()([up4, s3])\n    outputs = layers.Conv2DTranspose(num_classes,16,strides=8,padding='same',activation='softmax')(f3)\n    return keras.Model(inputs, outputs, name=\"FCN\")\n\n# SegNet\ndef build_segnet(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(inputs); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x);     x = layers.BatchNormalization()(x); x = layers.MaxPooling2D(2)(x)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x); x = layers.MaxPooling2D(2)(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x); x = layers.MaxPooling2D(2)(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x); x = layers.MaxPooling2D(2)(x)\n    x = layers.UpSampling2D(2)(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(512,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.UpSampling2D(2)(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(256,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.UpSampling2D(2)(x)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(128,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.UpSampling2D(2)(x)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(64,3,padding='same',activation='relu')(x); x = layers.BatchNormalization()(x)\n    outputs = layers.Conv2D(num_classes,1,activation='softmax')(x)\n    return keras.Model(inputs, outputs, name=\"SegNet\")\n\n# ============ Loss and Metrics ============\nSMOOTH = 1e-6\n\ndef _resize_to_label(y_pred, y_true):\n    ph = tf.shape(y_pred)[1]; pw = tf.shape(y_pred)[2]\n    th = tf.shape(y_true)[1]; tw = tf.shape(y_true)[2]\n    need = tf.logical_or(tf.not_equal(ph, th), tf.not_equal(pw, tw))\n    def _do(): return tf.image.resize(y_pred, (th, tw), method='bilinear')\n    return tf.cond(need, _do, lambda: y_pred)\n\ndef weighted_ce(y_true, y_pred):\n    y_pred = _resize_to_label(y_pred, y_true)\n    w = tf.reduce_sum(CLASS_WEIGHTS * y_true, axis=-1)\n    ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n    return tf.reduce_mean(ce * w)\n\ndef focal_tversky_loss(y_true, y_pred, alpha=0.8, beta=0.2, gamma=0.9, exclude_bg=True):\n    y_pred = _resize_to_label(y_pred, y_true)\n    if exclude_bg:\n        y_true = y_true[...,1:]; y_pred = y_pred[...,1:]\n    y_true_f = tf.reshape(y_true, [-1, tf.shape(y_true)[-1]])\n    y_pred_f = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])\n    tp = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n    fp = tf.reduce_sum((1. - y_true_f) * y_pred_f, axis=0)\n    fn = tf.reduce_sum(y_true_f * (1. - y_pred_f), axis=0)\n    t = (tp + SMOOTH) / (tp + alpha*fn + beta*fp + SMOOTH)\n    ft = tf.pow(1. - t, gamma)\n    return tf.reduce_mean(ft)\n\ndef combo_loss_stronger(y_true, y_pred, alpha=0.5):\n    return alpha * weighted_ce(y_true, y_pred) + (1.0 - alpha) * focal_tversky_loss(y_true, y_pred)\n\n@tf.function\ndef iou_no_bg(y_true, y_pred):\n    y_pred = _resize_to_label(y_pred, y_true)\n    yt = tf.argmax(y_true, -1); yp = tf.argmax(y_pred, -1)\n    yt_oh = tf.one_hot(yt, NUM_CLASSES, dtype=tf.float32)\n    yp_oh = tf.one_hot(yp, NUM_CLASSES, dtype=tf.float32)\n    inter = tf.reduce_sum(yt_oh * yp_oh, axis=[0,1,2])\n    union = tf.reduce_sum(yt_oh + yp_oh - yt_oh*yp_oh, axis=[0,1,2])\n    inter_nb = inter[1:]; union_nb = union[1:]\n    iou = tf.where(union_nb > 0.0, inter_nb / (union_nb + 1e-7), 0.0)\n    return tf.reduce_mean(iou)\n\n@tf.function\ndef iou_disease_only(y_true, y_pred):\n    \"\"\"Mean IoU over classes 2..C-1 (diseases only).\"\"\"\n    y_pred = _resize_to_label(y_pred, y_true)\n    yt = tf.argmax(y_true, -1); yp = tf.argmax(y_pred, -1)\n    yt_oh = tf.one_hot(yt, NUM_CLASSES, dtype=tf.float32)\n    yp_oh = tf.one_hot(yp, NUM_CLASSES, dtype=tf.float32)\n    inter = tf.reduce_sum(yt_oh * yp_oh, axis=[0,1,2])\n    union = tf.reduce_sum(yt_oh + yp_oh - yt_oh*yp_oh, axis=[0,1,2])\n    inter_dz = inter[2:]; union_dz = union[2:]\n    iou = tf.where(union_dz > 0.0, inter_dz / (union_dz + 1e-7), 0.0)\n    return tf.reduce_mean(iou)\n\ndef compile_model(model, lr=1e-3):\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=lr),\n        loss=combo_loss_stronger,\n        metrics=[iou_no_bg, iou_disease_only, 'accuracy']\n    )\n    return model\n\ndef plot_history(hist, title, outdir):\n    plt.figure(figsize=(11,4))\n    plt.subplot(1,3,1)\n    plt.plot(hist.history.get('loss', []), label='train')\n    plt.plot(hist.history.get('val_loss', []), label='val')\n    plt.title('Loss'); plt.legend()\n    plt.subplot(1,3,2)\n    plt.plot(hist.history.get('iou_no_bg', []), label='train')\n    plt.plot(hist.history.get('val_iou_no_bg', []), label='val')\n    plt.title('IoU (no-bg)'); plt.legend()\n    plt.subplot(1,3,3)\n    plt.plot(hist.history.get('iou_disease_only', []), label='train')\n    plt.plot(hist.history.get('val_iou_disease_only', []), label='val')\n    plt.title('IoU (disease-only)'); plt.legend()\n    plt.tight_layout()\n    os.makedirs(outdir, exist_ok=True)\n    p = os.path.join(outdir, f'{title}_curves.png')\n    plt.savefig(p, dpi=140, bbox_inches='tight'); plt.close()\n    return p\n\ndef compute_auto_class_weights(Y_int, num_classes):\n    counts = np.bincount(Y_int.flatten(), minlength=num_classes).astype(np.float64)\n    p = counts / max(1, counts.sum())\n    w = 1.0 / np.log(1.02 + p + 1e-12)  # inverse log frequency\n    w[0] = max(w[0]*0.5, 0.25)          # don't over-weight background\n    return w\n\n# ============ Main ============\ndef main():\n    t0 = time.time()\n    print(\"🔎 Loading dataset...\")\n    ds = AppleLeafDataset(BASE_DIR, IMG_SIZE)\n    X, Y = ds.load()\n\n    # splits ≈70/15/15\n    Xtr, Xte, Ytr, Yte = train_test_split(X, Y, test_size=0.15, random_state=SEED, shuffle=True)\n    Xtr, Xva, Ytr, Yva = train_test_split(Xtr, Ytr, test_size=0.1765, random_state=SEED, shuffle=True)\n    print(f\"Shapes -> Train: {Xtr.shape}, Val: {Xva.shape}, Test: {Xte.shape}\")\n\n    # class weights\n    if AUTO_CLASS_WEIGHTS:\n        global CLASS_WEIGHTS\n        CLASS_WEIGHTS = tf.constant(compute_auto_class_weights(Ytr, NUM_CLASSES), dtype=tf.float32)\n        print(\"Class weights (auto):\", CLASS_WEIGHTS.numpy())\n\n    # training dataset (oversampled) and eval datasets\n    if OVERSAMPLE_DISEASE:\n        train_ds = make_weighted_train_ds(Xtr, Ytr, BATCH_SIZE, augment=True)\n    else:\n        train_ds = make_dataset(Xtr, Ytr, BATCH_SIZE, shuffle=True, augment=True)\n    val_ds   = make_dataset(Xva, Yva, BATCH_SIZE, shuffle=False, augment=False)\n    test_ds  = make_dataset(Xte, Yte, BATCH_SIZE, shuffle=False, augment=False)\n\n    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n\n    builders = {\n        'UNet_MobileNetV2': build_unet_mobilenetv2,\n        'UNet': build_unet,\n        'DeepLabV3Plus': build_deeplabv3plus,\n        'FCN': build_fcn,\n        'SegNet': build_segnet\n    }\n\n    model_names = list(builders.keys())\n    if START_AT and START_AT in model_names:\n        model_names = model_names[model_names.index(START_AT):]\n    if RUN_ONLY:\n        model_names = [n for n in model_names if n in RUN_ONLY]\n\n    results = []\n    os.makedirs(OUTDIR, exist_ok=True)\n\n    for name in model_names:\n        tf.keras.backend.clear_session()\n        ckpt_path = os.path.join(OUTDIR, f\"{name}_best.keras\")\n\n        if SKIP_TRAIN_IF_CKPT and os.path.exists(ckpt_path):\n            print(f\"⏭️  {name}: checkpoint found -> loading for eval\")\n            try:\n                model = keras.models.load_model(ckpt_path, compile=False,\n                                                custom_objects={'iou_no_bg': iou_no_bg,\n                                                                'iou_disease_only': iou_disease_only,\n                                                                'combo_loss_stronger': combo_loss_stronger})\n                compile_model(model, lr=1e-3)\n            except Exception as e:\n                print(f\"⚠️  Failed to load {name} checkpoint: {e}\")\n                print(\"🔄 Training from scratch...\")\n                model = builders[name](input_shape, NUM_CLASSES)\n                # training branch below\n                pass\n\n        if not (SKIP_TRAIN_IF_CKPT and os.path.exists(ckpt_path)):\n            print(f\"\\n🚀 Training {name} ...\")\n            model = builders[name](input_shape, NUM_CLASSES)\n\n            # Two-phase fine-tune if pretrained encoder exists\n            if hasattr(model, \"_encoder\"):\n                # Phase 1: freeze encoder\n                model._encoder.trainable = False\n                compile_model(model, lr=1e-3)\n                hist1 = model.fit(train_ds, validation_data=val_ds,\n                                  epochs=max(4, EPOCHS//2), verbose=1)\n                # Phase 2: unfreeze encoder\n                model._encoder.trainable = True\n                compile_model(model, lr=3e-4)\n                cbs = [\n                    keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_iou_disease_only', mode='max',\n                                                    save_best_only=True, save_weights_only=False, verbose=1),\n                    keras.callbacks.EarlyStopping(monitor='val_iou_disease_only', mode='max',\n                                                  patience=8, restore_best_weights=True),\n                    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3,\n                                                      min_lr=1e-5, verbose=1)\n                ]\n                hist2 = model.fit(train_ds, validation_data=val_ds,\n                                  initial_epoch=max(4, EPOCHS//2), epochs=EPOCHS, verbose=1, callbacks=cbs)\n                _ = plot_history(hist2, name, OUTDIR)\n            else:\n                compile_model(model, lr=1e-3)\n                cbs = [\n                    keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_iou_disease_only', mode='max',\n                                                    save_best_only=True, save_weights_only=False, verbose=1),\n                    keras.callbacks.EarlyStopping(monitor='val_iou_disease_only', mode='max',\n                                                  patience=8, restore_best_weights=True),\n                    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3,\n                                                      min_lr=1e-5, verbose=1)\n                ]\n                hist = model.fit(train_ds, validation_data=val_ds,\n                                 epochs=EPOCHS, verbose=1, callbacks=cbs)\n                _ = plot_history(hist, name, OUTDIR)\n\n        # Evaluate (val + test)\n        print(f\"📏 Evaluating {name} ...\")\n        val_metrics  = model.evaluate(val_ds,  verbose=0)\n        test_metrics = model.evaluate(test_ds, verbose=0)\n\n        # Keras orders: [loss, iou_no_bg, iou_disease_only, accuracy]\n        res = {\n            \"Model\": name,\n            \"Val Loss\": float(val_metrics[0]),\n            \"Val IoU(no-bg)\": float(val_metrics[1]),\n            \"Val IoU(disease)\": float(val_metrics[2]),\n            \"Val Acc\": float(val_metrics[3]),\n            \"Test Loss\": float(test_metrics[0]),\n            \"Test IoU(no-bg)\": float(test_metrics[1]),\n            \"Test IoU(disease)\": float(test_metrics[2]),\n            \"Test Acc\": float(test_metrics[3]),\n        }\n        results.append(res)\n\n        # Visual previews with severity\n        _ = visualize_with_severity(model, Xva, Yva, n=4, outdir=OUTDIR)\n        _ = visualize_grid_with_severity(model, Xva, Yva, k=6, outdir=OUTDIR,\n                                         title=f\"{name} — WeightedCE + Focal-Tversky\")\n\n    # Save/append comparison CSV\n    cmp_csv = os.path.join(OUTDIR, \"model_comparison.csv\")\n    df_new = pd.DataFrame(results)\n    if os.path.exists(cmp_csv):\n        try:\n            df_old = pd.read_csv(cmp_csv)\n            df = (pd.concat([df_old, df_new], ignore_index=True)\n                    .drop_duplicates(subset=['Model'], keep='last'))\n        except Exception:\n            df = df_new\n    else:\n        df = df_new\n    df = df.sort_values(\"Val IoU(disease)\", ascending=False)\n    df.to_csv(cmp_csv, index=False)\n    print(\"\\n================ Model Comparison (by Val IoU disease-only) ================\")\n    print(df.to_string(index=False))\n    print(f\"\\n💾 Saved: {cmp_csv}\")\n    print(f\"✅ Done in {time.time()-t0:.1f}s\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T06:49:23.500119Z","iopub.execute_input":"2025-08-31T06:49:23.501046Z","iopub.status.idle":"2025-08-31T06:50:01.054383Z","shell.execute_reply.started":"2025-08-31T06:49:23.501018Z","shell.execute_reply":"2025-08-31T06:50:01.053451Z"}},"outputs":[{"name":"stdout","text":"⚠️  GPU mem-growth not set: Physical devices cannot be modified after being initialized\n🔎 Loading dataset...\n📂 Alternaria leaf spot | imgs: 278 | masks: 278 | paired: 278\n📂 Brown spot           | imgs: 215 | masks: 215 | paired: 215\n📂 Gray spot            | imgs: 395 | masks: 395 | paired: 395\n📂 Healthy leaf         | imgs: 409 | masks: 409 | paired: 409\n📂 Rust                 | imgs: 344 | masks: 344 | paired: 344\n✅ Paired samples: 1641\n","output_type":"stream"},{"name":"stderr","text":"Loading data: 100%|██████████| 1641/1641 [00:20<00:00, 80.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Shapes -> Train: (1147, 256, 256, 3), Val: (247, 256, 256, 3), Test: (247, 256, 256, 3)\nClass weights (auto): [ 0.9594292  3.3929112 41.759647  48.69141   47.26587   37.653244 ]\n⏭️  UNet_MobileNetV2: checkpoint found -> loading for eval\n⚠️  Failed to load UNet_MobileNetV2 checkpoint: The `{arg_name}` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization().\n🔄 Training from scratch...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/78845969.py:403: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  base = tf.keras.applications.MobileNetV2(\n","output_type":"stream"},{"name":"stdout","text":"📏 Evaluating UNet_MobileNetV2 ...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/78845969.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/78845969.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;31m# Evaluate (val + test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"📏 Evaluating {name} ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mval_metrics\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m         \u001b[0mtest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\u001b[0m in \u001b[0;36m_assert_compile_called\u001b[0;34m(self, method_name)\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"calling `{method_name}()`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_symbolic_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: You must call `compile()` before using the model."],"ename":"ValueError","evalue":"You must call `compile()` before using the model.","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Path to your image\nimg_path = \"/kaggle/input/apple-dataset/ATLDSD/Alternaria leaf spot/image/000413.jpg\"\n\n# Load the image\nimg = mpimg.imread(img_path)\n\n# Display the image\nplt.imshow(img)\nplt.axis(\"off\")  # Hide axes\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}